# test_gpt_analyzer.py
"""
GPT ì¤‘ì‹¬ ë³´ì•ˆ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
"""
import sys
import os
sys.path.append('.')

from dotenv import load_dotenv
load_dotenv()

from core.llm_analyzer import LLMSecurityAnalyzer
import json
import time
from typing import Dict, List  # íƒ€ì… íŒíŠ¸ import ì¶”ê°€

def test_vulnerable_code():
    """ë‹¤ì–‘í•œ ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ğŸ” GPT ì¤‘ì‹¬ ë³´ì•ˆ ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    vulnerable_code = """
import sqlite3
import pickle
import hashlib
import os
from flask import Flask, request, render_template_string

app = Flask(__name__)

# í•˜ë“œì½”ë”©ëœ ë¹„ë°€ ì •ë³´
DB_PASSWORD = "admin123"
API_KEY = "sk-1234567890abcdef"

def get_user(user_id):
    # SQL ì¸ì ì…˜ ì·¨ì•½ì 
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    query = f"SELECT * FROM users WHERE id = {user_id}"
    cursor.execute(query)
    return cursor.fetchall()

def authenticate(username, password):
    # ì•½í•œ í•´ì‹œ ì•Œê³ ë¦¬ì¦˜
    password_hash = hashlib.md5(password.encode()).hexdigest()
    
    # SQL ì¸ì ì…˜ (ë˜ ë‹¤ë¥¸ í˜•íƒœ)
    query = "SELECT * FROM users WHERE username='%s' AND password='%s'" % (username, password_hash)
    return execute_query(query)

@app.route('/search')
def search():
    # XSS ì·¨ì•½ì 
    keyword = request.args.get('q', '')
    return render_template_string(f"<h1>ê²€ìƒ‰ ê²°ê³¼: {keyword}</h1>")

def load_data(data_bytes):
    # ì•ˆì „í•˜ì§€ ì•Šì€ ì—­ì§ë ¬í™”
    return pickle.loads(data_bytes)

def process_file(filename):
    # ê²½ë¡œ ì¡°ì‘ ì·¨ì•½ì 
    filepath = f"/uploads/{filename}"
    with open(filepath, 'r') as f:
        return f.read()

def execute_command(cmd):
    # ëª…ë ¹ì–´ ì‚½ì…
    os.system(f"echo Processing: {cmd}")

# ì˜ëª»ëœ ì˜ˆì™¸ ì²˜ë¦¬
def divide(a, b):
    try:
        return a / b
    except:
        pass  # ëª¨ë“  ì˜ˆì™¸ ë¬´ì‹œ
"""
    
    print("\nğŸ“ ë¶„ì„í•  ì½”ë“œ (ì—¬ëŸ¬ ì·¨ì•½ì  í¬í•¨)")
    print(f"   ì´ {len(vulnerable_code.split(chr(10)))}ì¤„")
    print("   í¬í•¨ëœ ì·¨ì•½ì  ìœ í˜•:")
    print("   - SQL Injection (2ê³³)")
    print("   - Hardcoded Secrets")
    print("   - Weak Cryptography")
    print("   - XSS")
    print("   - Insecure Deserialization")
    print("   - Path Traversal")
    print("   - Command Injection")
    print("   - Poor Error Handling")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    print("\nğŸš€ GPT ë³´ì•ˆ ë¶„ì„ê¸° ì´ˆê¸°í™”...")
    try:
        analyzer = LLMSecurityAnalyzer()
        print("âœ… ì´ˆê¸°í™” ì„±ê³µ")
        print(f"   - GPT ëª¨ë¸: {analyzer.model}")
        print(f"   - RAG ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if analyzer.rag_available else 'ì•„ë‹ˆì˜¤'}")
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # ë¶„ì„ ì‹¤í–‰
    print("\nğŸ” ë³´ì•ˆ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
    start_time = time.time()
    
    result = analyzer.analyze_code_security(vulnerable_code)
    
    elapsed_time = time.time() - start_time
    print(f"âœ… ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
    
    if result.get('success'):
        display_results(result['analysis'], result.get('metadata', {}))
    else:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error')}")
    
    return result

def test_safe_code():
    """ì•ˆì „í•œ ì½”ë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ğŸ” ì•ˆì „í•œ ì½”ë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    safe_code = """
import sqlite3
import hashlib
import secrets
import os
from flask import Flask, request, render_template

app = Flask(__name__)

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
DB_PASSWORD = os.environ.get('DB_PASSWORD')
API_KEY = os.environ.get('API_KEY')

def get_user(user_id):
    # íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    query = "SELECT * FROM users WHERE id = ?"
    cursor.execute(query, (user_id,))
    return cursor.fetchall()

def authenticate(username, password):
    # ê°•ë ¥í•œ í•´ì‹œ ì•Œê³ ë¦¬ì¦˜
    salt = secrets.token_bytes(32)
    password_hash = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)
    
    # íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬
    query = "SELECT * FROM users WHERE username = ? AND password = ?"
    return execute_query(query, (username, password_hash))

@app.route('/search')
def search():
    # í…œí”Œë¦¿ ì—”ì§„ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë Œë”ë§
    keyword = request.args.get('q', '')
    return render_template('search.html', keyword=keyword)
"""
    
    print("\nğŸ“ ë¶„ì„í•  ì½”ë“œ (ì•ˆì „í•œ ì½”ë“œ)")
    print(f"   ì´ {len(safe_code.split(chr(10)))}ì¤„")
    
    # ë¶„ì„ ì‹¤í–‰
    try:
        analyzer = LLMSecurityAnalyzer()
        print("\nğŸ” ë³´ì•ˆ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        
        result = analyzer.analyze_code_security(safe_code)
        
        if result.get('success'):
            analysis = result['analysis']
            print(f"\nâœ… ë¶„ì„ ì™„ë£Œ")
            print(f"ğŸ¯ ë³´ì•ˆ ì ìˆ˜: {analysis['security_score']}/100")
            
            if analysis['code_vulnerabilities']:
                print(f"âš ï¸ ë°œê²¬ëœ ì´ìŠˆ: {len(analysis['code_vulnerabilities'])}ê°œ")
            else:
                print("âœ… ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                
            print(f"\nğŸ“Œ ìš”ì•½: {analysis['summary']}")
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")

def display_results(analysis: Dict, metadata: Dict):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    print("=" * 70)
    
    # ìš”ì•½
    print(f"\nğŸ“Œ ìš”ì•½: {analysis['summary']}")
    print(f"ğŸ¯ ë³´ì•ˆ ì ìˆ˜: {analysis['security_score']}/100")
    
    # ë©”íƒ€ë°ì´í„°
    if metadata:
        print(f"\nğŸ“‹ ë¶„ì„ ì •ë³´:")
        print(f"   - ì‚¬ìš© ëª¨ë¸: {metadata.get('gpt_model', 'unknown')}")
        print(f"   - RAG ì‚¬ìš©: {metadata.get('rag_available', False)}")
        print(f"   - ì´ ì·¨ì•½ì : {metadata.get('total_vulnerabilities', 0)}ê°œ")
    
    # ì·¨ì•½ì  ìƒì„¸
    vulns = analysis.get('code_vulnerabilities', [])
    if vulns:
        print(f"\nâš ï¸ ë°œê²¬ëœ ì·¨ì•½ì  ({len(vulns)}ê°œ):")
        
        # ì‹¬ê°ë„ë³„ ê·¸ë£¹í™”
        by_severity = {'CRITICAL': [], 'HIGH': [], 'MEDIUM': [], 'LOW': []}
        for vuln in vulns:
            severity = vuln.get('severity', 'MEDIUM')
            by_severity[severity].append(vuln)
        
        for severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
            if by_severity[severity]:
                print(f"\n{'ğŸ”´' if severity == 'CRITICAL' else 'ğŸŸ ' if severity == 'HIGH' else 'ğŸŸ¡' if severity == 'MEDIUM' else 'ğŸŸ¢'} {severity} ({len(by_severity[severity])}ê°œ):")
                
                for vuln in by_severity[severity]:
                    lines = vuln.get('line_numbers', [])
                    line_str = f"ë¼ì¸ {lines[0]}" if lines else "ìœ„ì¹˜ ë¶ˆëª…"
                    
                    print(f"\n   [{line_str}] {vuln['type']}")
                    print(f"   ğŸ“ ì„¤ëª…: {vuln.get('description', '')[:100]}...")
                    
                    # ì„¤ëª… ì¶œì²˜ í‘œì‹œ
                    if 'explanation' in vuln:
                        source = vuln.get('explanation_source', 'unknown')
                        if source == 'KISIA ê°€ì´ë“œë¼ì¸':
                            print(f"   ğŸ“š {source}: {vuln['explanation'][:150]}...")
                        else:
                            print(f"   ğŸ¤– {source}: {vuln['explanation'][:100]}...")
                    
                    # ìˆ˜ì • ë°©ë²•
                    if vuln.get('recommended_fix'):
                        print(f"   âœ… ê¶Œì¥ ìˆ˜ì •: {vuln['recommended_fix'][:100]}...")
                    
                    # ì·¨ì•½í•œ ì½”ë“œ
                    if vuln.get('vulnerable_code'):
                        print(f"   ğŸ’» ì·¨ì•½í•œ ì½”ë“œ: {vuln['vulnerable_code'][:50]}...")
    
    # ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
    actions = analysis.get('immediate_actions', [])
    if actions:
        print(f"\nğŸš¨ ì¦‰ì‹œ í•„ìš”í•œ ì¡°ì¹˜:")
        for action in actions:
            print(f"   â€¢ {action}")
    
    # ëª¨ë²” ì‚¬ë¡€
    practices = analysis.get('best_practices', [])
    if practices:
        print(f"\nğŸ’¡ ê¶Œì¥ ë³´ì•ˆ ì‚¬ë¡€:")
        for practice in practices:
            print(f"   â€¢ {practice}")

def save_results(result: Dict, filename: str = "gpt_analysis_result.json"):
    """ê²°ê³¼ ì €ì¥"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {filename}")

def main():
    print("ğŸš€ GPT ì¤‘ì‹¬ ë³´ì•ˆ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸\n")
    
    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    print("í…ŒìŠ¤íŠ¸ ì„ íƒ:")
    print("1. ì·¨ì•½í•œ ì½”ë“œ ë¶„ì„")
    print("2. ì•ˆì „í•œ ì½”ë“œ ë¶„ì„")
    print("3. ë‘˜ ë‹¤ í…ŒìŠ¤íŠ¸")
    
    choice = input("\nì„ íƒ (1-3): ").strip()
    
    results = []
    
    if choice == '1':
        result = test_vulnerable_code()
        if result:
            results.append(result)
    elif choice == '2':
        test_safe_code()
    elif choice == '3':
        result = test_vulnerable_code()
        if result:
            results.append(result)
        test_safe_code()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return
    
    # ê²°ê³¼ ì €ì¥ ì˜µì…˜
    if results:
        save_option = input("\nğŸ’¾ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if save_option == 'y':
            for i, result in enumerate(results):
                filename = f"gpt_analysis_result_{i+1}.json" if len(results) > 1 else "gpt_analysis_result.json"
                save_results(result, filename)

if __name__ == "__main__":
    main()