# core/github_branch_analyzer.py
"""
GitHub ë¸Œëœì¹˜ ë¹„êµ ë° diff ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ ëª¨ë“ˆ
Pull Request ì „ ë¸Œëœì¹˜ ê°„ ë³€ê²½ì‚¬í•­ë§Œ ì„ íƒì ìœ¼ë¡œ ê²€ì‚¬
"""
import os
import re
import json
import tempfile
import shutil
from typing import Dict, List, Optional, Tuple, Set
from pathlib import Path
import requests
from datetime import datetime
import base64
import urllib.parse
import urllib.parse

try:
    import git
    from git import Repo
    GIT_AVAILABLE = True
except ImportError:
    GIT_AVAILABLE = False
    print("âš ï¸ GitPythonì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install GitPython")


class GitHubBranchAnalyzer:
    """GitHub ë¸Œëœì¹˜ ë¹„êµ ë° diff ë¶„ì„ê¸°"""
    
    def __init__(self, github_token: Optional[str] = None):
        """
        Args:
            github_token: GitHub API í† í° (private repo ì ‘ê·¼ìš©, ì„ íƒì‚¬í•­)
        """
        self.github_token = github_token or os.getenv("GITHUB_TOKEN")
        self.api_base = "https://api.github.com"
        self.headers = {
            "Accept": "application/vnd.github.v3+json"
        }
        if self.github_token:
            self.headers["Authorization"] = f"token {self.github_token}"
        
        self.temp_dir = None
        self.repo_path = None
        
    def get_branches(self, repo_url: str) -> Dict[str, List[Dict]]:
        """
        ë ˆí¬ì§€í† ë¦¬ì˜ ëª¨ë“  ë¸Œëœì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            repo_url: GitHub ë ˆí¬ì§€í† ë¦¬ URL
            
        Returns:
            ë¸Œëœì¹˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # URLì—ì„œ owner/repo ì¶”ì¶œ
            owner, repo = self._parse_github_url(repo_url)
            if not owner or not repo:
                return {"success": False, "error": "Invalid GitHub URL", "branches": []}
            
            # GitHub APIë¡œ ë¸Œëœì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            api_url = f"{self.api_base}/repos/{owner}/{repo}/branches"
            
            branches = []
            page = 1
            
            while True:
                response = requests.get(
                    api_url,
                    headers=self.headers,
                    params={"page": page, "per_page": 100}
                )
                
                if response.status_code == 404:
                    return {"success": False, "error": "Repository not found", "branches": []}
                elif response.status_code == 403:
                    return {"success": False, "error": "API rate limit exceeded", "branches": []}
                elif response.status_code != 200:
                    return {"success": False, "error": f"API error: {response.status_code}", "branches": []}
                
                page_branches = response.json()
                if not page_branches:
                    break
                    
                for branch in page_branches:
                    branches.append({
                        "name": branch["name"],
                        "sha": branch["commit"]["sha"],
                        "protected": branch.get("protected", False),
                        "commit_url": branch["commit"]["url"],
                        "commit_date": self._get_commit_date(branch["commit"]["url"])
                    })
                
                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                if len(page_branches) < 100:
                    break
                page += 1
            
            # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹  ë¨¼ì €)
            branches.sort(key=lambda x: x["commit_date"] if x["commit_date"] else "", reverse=True)
            
            # ê¸°ë³¸ ë¸Œëœì¹˜ ì°¾ê¸°
            default_branch = self._get_default_branch(owner, repo)
            
            return {
                "success": True,
                "owner": owner,
                "repo": repo,
                "default_branch": default_branch,
                "branches": branches,
                "total": len(branches)
            }
            
        except Exception as e:
            return {"success": False, "error": str(e), "branches": []}
    
    def get_branch_diff(self, repo_url: str, base_branch: str, compare_branch: str) -> Dict:
        """
        ë‘ ë¸Œëœì¹˜ ê°„ diff ê°€ì ¸ì˜¤ê¸°
        
        Args:
            repo_url: GitHub ë ˆí¬ì§€í† ë¦¬ URL
            base_branch: ê¸°ì¤€ ë¸Œëœì¹˜ (ì˜ˆ: main)
            compare_branch: ë¹„êµ ë¸Œëœì¹˜ (ì˜ˆ: feature/new-feature)
            
        Returns:
            diff ì •ë³´
        """
        try:
            owner, repo = self._parse_github_url(repo_url)
            if not owner or not repo:
                return {"success": False, "error": "Invalid GitHub URL"}
            
            # GitHub APIë¡œ ë¹„êµ (ë¸Œëœì¹˜ëª… URL ì¸ì½”ë”©: feature/foo ë“± ìŠ¬ë˜ì‹œ í¬í•¨ ì¼€ì´ìŠ¤ ëŒ€ì‘)
            base_enc = urllib.parse.quote(base_branch, safe='')
            compare_enc = urllib.parse.quote(compare_branch, safe='')
            api_url = f"{self.api_base}/repos/{owner}/{repo}/compare/{base_enc}...{compare_enc}"
            
            response = requests.get(api_url, headers=self.headers)
            
            if response.status_code != 200:
                return {
                    "success": False, 
                    "error": f"Failed to get diff: {response.status_code}"
                }
            
            data = response.json()
            
            # íŒŒì¼ë³„ ë³€ê²½ì‚¬í•­ ì •ë¦¬
            files_changed = []
            total_additions = 0
            total_deletions = 0
            
            for file in data.get("files", []):
                # Python íŒŒì¼ë§Œ í•„í„°ë§ (ì„ íƒì‚¬í•­)
                if file["filename"].endswith(".py"):
                    file_info = {
                        "filename": file["filename"],
                        "status": file["status"],  # added, modified, removed, renamed
                        "additions": file["additions"],
                        "deletions": file["deletions"],
                        "changes": file["changes"],
                        "patch": file.get("patch", ""),  # diff ë‚´ìš©
                        "blob_url": file.get("blob_url", ""),
                        "raw_url": file.get("raw_url", ""),
                        "contents_url": file.get("contents_url", "")
                    }
                    
                    # ì¶”ê°€/ìˆ˜ì •ëœ ë¼ì¸ë§Œ ì¶”ì¶œ
                    if file.get("patch"):
                        file_info["added_lines"] = self._extract_added_lines(file["patch"])
                        file_info["removed_lines"] = self._extract_removed_lines(file["patch"])
                    
                    files_changed.append(file_info)
                    total_additions += file["additions"]
                    total_deletions += file["deletions"]
            
            return {
                "success": True,
                "base_branch": base_branch,
                "compare_branch": compare_branch,
                "ahead_by": data.get("ahead_by", 0),
                "behind_by": data.get("behind_by", 0),
                "total_commits": data.get("total_commits", 0),
                "files_changed": files_changed,
                "total_files": len(files_changed),
                "total_additions": total_additions,
                "total_deletions": total_deletions,
                "mergeable": data.get("mergeable_state", "unknown"),
                "commits": self._extract_commit_info(data.get("commits", []))
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}

    def list_pull_requests(self, repo_url: str, state: str = "open") -> Dict:
        """
        PR ëª©ë¡ ì¡°íšŒ (ê¸°ë³¸: ì˜¤í”ˆ ìƒíƒœ = ë¯¸ë³‘í•© PR)

        Args:
            repo_url: GitHub ë ˆí¬ì§€í† ë¦¬ URL ë˜ëŠ” owner/repo ë¬¸ìì—´ í¬í•¨ URL
            state: open | closed | all

        Returns:
            { success, owner, repo, pull_requests: [ {number, title, user, created_at, updated_at, head, base} ], total }
        """
        try:
            owner, repo = self._parse_github_url(repo_url)
            if not owner or not repo:
                return {"success": False, "error": "Invalid GitHub URL", "pull_requests": []}

            api_url = f"{self.api_base}/repos/{owner}/{repo}/pulls"

            pulls = []
            page = 1
            while True:
                resp = requests.get(
                    api_url,
                    headers=self.headers,
                    params={"state": state, "page": page, "per_page": 100},
                )
                if resp.status_code != 200:
                    return {"success": False, "error": f"API error: {resp.status_code}", "pull_requests": []}

                page_items = resp.json() or []
                if not page_items:
                    break

                for pr in page_items:
                    pulls.append({
                        "number": pr.get("number"),
                        "title": pr.get("title", ""),
                        "user": (pr.get("user") or {}).get("login"),
                        "created_at": pr.get("created_at"),
                        "updated_at": pr.get("updated_at"),
                        "head": {
                            "ref": (pr.get("head") or {}).get("ref"),
                            "sha": (pr.get("head") or {}).get("sha"),
                            "repo": ((pr.get("head") or {}).get("repo") or {}).get("full_name"),
                        },
                        "base": {
                            "ref": (pr.get("base") or {}).get("ref"),
                            "sha": (pr.get("base") or {}).get("sha"),
                            "repo": ((pr.get("base") or {}).get("repo") or {}).get("full_name"),
                        },
                        "draft": pr.get("draft", False),
                        "mergeable": None,
                    })

                if len(page_items) < 100:
                    break
                page += 1

            # ìµœì‹  ì—…ë°ì´íŠ¸ ìˆœìœ¼ë¡œ ì •ë ¬
            pulls.sort(key=lambda x: x.get("updated_at") or "", reverse=True)

            return {
                "success": True,
                "owner": owner,
                "repo": repo,
                "pull_requests": pulls,
                "total": len(pulls),
            }
        except Exception as e:
            return {"success": False, "error": str(e), "pull_requests": []}

    def get_pull_request_diff_code(self, repo_url: str, pull_number: int) -> Dict:
        """
        íŠ¹ì • PRì˜ ë³€ê²½ íŒŒì¼ ëª©ë¡ê³¼ ì½”ë“œ ìˆ˜ì§‘

        - ì¶”ê°€ëœ ë¼ì¸ë§Œ ê²°í•©í•œ ì½”ë“œì™€ ë³€ê²½ íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©ì„ ëª¨ë‘ ì œê³µ
        - ì „ì²´ ë‚´ìš©ì€ added/modified/renamed íŒŒì¼ì— ëŒ€í•´ì„œë§Œ ì‹œë„

        Returns:
            { success, file_analysis, combined_added_code, combined_full_code, base_ref, head_ref }
        """
        try:
            owner, repo = self._parse_github_url(repo_url)
            if not owner or not repo:
                return {"success": False, "error": "Invalid GitHub URL"}

            # PR ë©”íƒ€ ì •ë³´ (base/head ë¸Œëœì¹˜ëª… í™•ë³´)
            pr_url = f"{self.api_base}/repos/{owner}/{repo}/pulls/{pull_number}"
            pr_resp = requests.get(pr_url, headers=self.headers)
            if pr_resp.status_code != 200:
                return {"success": False, "error": f"PR fetch failed: {pr_resp.status_code}"}
            pr_data = pr_resp.json()
            base_ref = (pr_data.get("base") or {}).get("ref")
            head_ref = (pr_data.get("head") or {}).get("ref")

            # íŒŒì¼ ë³€ê²½ ëª©ë¡ (pagination ëŒ€ì‘)
            files_url = f"{self.api_base}/repos/{owner}/{repo}/pulls/{pull_number}/files"
            all_files = []
            page = 1
            while True:
                resp = requests.get(files_url, headers=self.headers, params={"page": page, "per_page": 100})
                if resp.status_code != 200:
                    return {"success": False, "error": f"Failed to get PR files: {resp.status_code}"}
                items = resp.json() or []
                if not items:
                    break
                all_files.extend(items)
                if len(items) < 100:
                    break
                page += 1

            file_analysis: List[Dict] = []
            combined_added_code_parts: List[str] = []
            combined_full_code_parts: List[str] = []

            for f in all_files:
                filename = f.get("filename", "")
                # Python íŒŒì¼ë§Œ ëŒ€ìƒìœ¼ë¡œ ì œí•œ
                if not filename.endswith('.py'):
                    continue
                status = f.get("status", "")
                additions = f.get("additions", 0)
                deletions = f.get("deletions", 0)
                patch = f.get("patch", "") or ""
                raw_url = f.get("raw_url") or ""
                contents_url = f.get("contents_url") or ""

                info = {
                    "filename": filename,
                    "status": status,
                    "additions": additions,
                    "deletions": deletions,
                }

                # ì¶”ê°€ëœ ë¼ì¸ë§Œ ì¶”ì¶œ
                if patch:
                    info["added_lines"] = self._extract_added_lines(patch)
                    info["removed_lines"] = self._extract_removed_lines(patch)
                    if info["added_lines"]:
                        added_code = "\n".join(info["added_lines"]).strip()
                        if added_code:
                            info["added_code"] = added_code
                            combined_added_code_parts.append(f"# ===== File: {filename} =====\n{added_code}\n")

                # ë³€ê²½/ì¶”ê°€ëœ íŒŒì¼ì˜ ì „ì²´ ë‚´ìš© ìˆ˜ì§‘ ì‹œë„
                if status in ["added", "modified", "renamed"]:
                    full_content = None
                    if raw_url:
                        full_content = self._get_file_content_raw(raw_url)
                    # contents_url í…œí”Œë¦¿ì€ ?ref=sha í¬í•¨ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ í˜¸ì¶œ ì‹œë„
                    if full_content is None and contents_url:
                        try:
                            c_resp = requests.get(contents_url, headers=self.headers)
                            if c_resp.status_code == 200:
                                data = c_resp.json()
                                if data.get("encoding") == "base64":
                                    full_content = base64.b64decode(data.get("content", "")).decode("utf-8", errors="ignore")
                                elif data.get("download_url"):
                                    full_content = self._get_file_content_raw(data.get("download_url"))
                        except Exception:
                            full_content = None

                    if full_content:
                        info["full_content"] = full_content
                        combined_full_code_parts.append(f"# ===== File: {filename} =====\n{full_content}\n")

                file_analysis.append(info)

            return {
                "success": True,
                "file_analysis": file_analysis,
                "combined_added_code": "\n".join(combined_added_code_parts),
                "combined_full_code": "\n".join(combined_full_code_parts),
                "base_ref": base_ref,
                "head_ref": head_ref,
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_diff_code_only(self, repo_url: str, base_branch: str, compare_branch: str, 
                          selected_files: Optional[List[str]] = None) -> Dict:
        """
        ì„ íƒëœ íŒŒì¼ë“¤ì˜ diff ì½”ë“œë§Œ ì¶”ì¶œ
        
        Args:
            repo_url: GitHub ë ˆí¬ì§€í† ë¦¬ URL
            base_branch: ê¸°ì¤€ ë¸Œëœì¹˜
            compare_branch: ë¹„êµ ë¸Œëœì¹˜
            selected_files: ë¶„ì„í•  íŒŒì¼ ëª©ë¡ (Noneì´ë©´ ëª¨ë“  ë³€ê²½ íŒŒì¼)
            
        Returns:
            diff ì½”ë“œì™€ ë¶„ì„ ì •ë³´
        """
        # ë¨¼ì € diff ê°€ì ¸ì˜¤ê¸°
        diff_result = self.get_branch_diff(repo_url, base_branch, compare_branch)
        
        if not diff_result["success"]:
            return diff_result
        
        # ì„ íƒëœ íŒŒì¼ í•„í„°ë§
        files_to_analyze = []
        if selected_files:
            for file_info in diff_result["files_changed"]:
                if file_info["filename"] in selected_files:
                    files_to_analyze.append(file_info)
        else:
            files_to_analyze = diff_result["files_changed"]
        
        # ì¶”ê°€/ìˆ˜ì •ëœ ì½”ë“œë§Œ ì¶”ì¶œ
        combined_added_code = []
        combined_full_code = []
        file_analysis = []
        
        for file_info in files_to_analyze:
            file_data = {
                "filename": file_info["filename"],
                "status": file_info["status"],
                "additions": file_info["additions"],
                "deletions": file_info["deletions"]
            }
            
            # ì¶”ê°€ëœ ë¼ì¸ë§Œ ê²°í•©
            if "added_lines" in file_info and file_info["added_lines"]:
                added_code = "\n".join(file_info["added_lines"])
                file_data["added_code"] = added_code
                combined_added_code.append(f"# ===== File: {file_info['filename']} =====\n{added_code}\n")
            
            # ì „ì²´ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (í•„ìš”ì‹œ) - renamed í¬í•¨, ì‹¤íŒ¨ ì‹œ raw_url í´ë°±
            if file_info["status"] in ["added", "modified", "renamed"]:
                full_content = self._get_file_content(repo_url, compare_branch, file_info["filename"])
                if not full_content and file_info.get("raw_url"):
                    full_content = self._get_file_content_raw(file_info["raw_url"])
                if full_content:
                    file_data["full_content"] = full_content
                    combined_full_code.append(f"# ===== File: {file_info['filename']} =====\n{full_content}\n")
            
            file_analysis.append(file_data)
        
        return {
            "success": True,
            "base_branch": base_branch,
            "compare_branch": compare_branch,
            "files_analyzed": len(file_analysis),
            "file_analysis": file_analysis,
            "combined_added_code": "\n".join(combined_added_code),  # ì¶”ê°€ëœ ì½”ë“œë§Œ
            "combined_full_code": "\n".join(combined_full_code),    # ì „ì²´ ì½”ë“œ
            "summary": {
                "total_additions": sum(f["additions"] for f in file_analysis),
                "total_deletions": sum(f["deletions"] for f in file_analysis),
                "added_files": sum(1 for f in file_analysis if f["status"] == "added"),
                "modified_files": sum(1 for f in file_analysis if f["status"] == "modified"),
                "removed_files": sum(1 for f in file_analysis if f["status"] == "removed")
            }
        }
    
    def analyze_branch_security(self, repo_url: str, base_branch: str, compare_branch: str,
                               analyze_mode: str = "diff_only") -> Dict:
        """
        ë¸Œëœì¹˜ì˜ ë³´ì•ˆ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            repo_url: GitHub ë ˆí¬ì§€í† ë¦¬ URL
            base_branch: ê¸°ì¤€ ë¸Œëœì¹˜
            compare_branch: ë¹„êµ ë¸Œëœì¹˜
            analyze_mode: "diff_only" (ë³€ê²½ì‚¬í•­ë§Œ) ë˜ëŠ” "full" (ì „ì²´ íŒŒì¼)
            
        Returns:
            ë³´ì•ˆ ë¶„ì„ ê²°ê³¼
        """
        # diff ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        code_result = self.get_diff_code_only(repo_url, base_branch, compare_branch)
        
        if not code_result["success"]:
            return code_result
        
        # ë¶„ì„í•  ì½”ë“œ ì„ íƒ
        if analyze_mode == "diff_only":
            code_to_analyze = code_result["combined_added_code"]
            analysis_scope = "ë³€ê²½ëœ ì½”ë“œë§Œ ë¶„ì„"
        else:
            code_to_analyze = code_result["combined_full_code"]
            analysis_scope = "ë³€ê²½ëœ íŒŒì¼ ì „ì²´ ë¶„ì„"
        
        # ì½”ë“œê°€ ì—†ìœ¼ë©´
        if not code_to_analyze.strip():
            return {
                "success": True,
                "base_branch": base_branch,
                "compare_branch": compare_branch,
                "analysis_scope": analysis_scope,
                "files_analyzed": 0,
                "message": "ë¶„ì„í•  Python ì½”ë“œ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤",
                "security_issues": [],
                "summary": code_result.get("summary", {}),
                "recommendation": "âœ… ë³€ê²½ì‚¬í•­ì´ ì—†ì–´ ë¨¸ì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            }
        
        # ì—¬ê¸°ì„œ ì‹¤ì œ ë³´ì•ˆ ë¶„ì„ ìˆ˜í–‰ (ê¸°ì¡´ ëª¨ë“ˆ í™œìš©)
        try:
            from core.improved_llm_analyzer import ImprovedSecurityAnalyzer
            
            analyzer = ImprovedSecurityAnalyzer()
            security_result = analyzer.analyze_security(code_to_analyze)
            
            return {
                "success": True,
                "base_branch": base_branch,
                "compare_branch": compare_branch,
                "analysis_scope": analysis_scope,
                "files_analyzed": code_result["files_analyzed"],
                "summary": code_result["summary"],
                "security_analysis": security_result,
                "recommendation": self._generate_pr_recommendation(security_result)
            }
            
        except ImportError:
            # ë³´ì•ˆ ë¶„ì„ ëª¨ë“ˆì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¶„ì„
            return {
                "success": True,
                "base_branch": base_branch,
                "compare_branch": compare_branch,
                "analysis_scope": analysis_scope,
                "files_analyzed": code_result["files_analyzed"],
                "summary": code_result["summary"],
                "code_to_analyze": code_to_analyze,
                "message": "ë³´ì•ˆ ë¶„ì„ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì½”ë“œë§Œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤."
            }
    
    def _parse_github_url(self, url: str) -> Tuple[Optional[str], Optional[str]]:
        """GitHub URLì—ì„œ ownerì™€ repo ì¶”ì¶œ"""
        patterns = [
            r'github\.com[/:]([^/]+)/([^/\.]+)',
            r'github\.com/([^/]+)/([^/]+)/.*'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                owner, repo = match.groups()[:2]
                # .git ì œê±°
                repo = repo.replace('.git', '')
                return owner, repo
        
        return None, None
    
    def _get_default_branch(self, owner: str, repo: str) -> Optional[str]:
        """ê¸°ë³¸ ë¸Œëœì¹˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            api_url = f"{self.api_base}/repos/{owner}/{repo}"
            response = requests.get(api_url, headers=self.headers)
            
            if response.status_code == 200:
                return response.json().get("default_branch", "main")
        except:
            pass
        
        return "main"
    
    def _get_commit_date(self, commit_url: str) -> Optional[str]:
        """ì»¤ë°‹ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = requests.get(commit_url, headers=self.headers)
            if response.status_code == 200:
                commit_data = response.json()
                return commit_data.get("commit", {}).get("author", {}).get("date")
        except:
            pass
        return None
    
    def _extract_added_lines(self, patch: str) -> List[str]:
        """diffì—ì„œ ì¶”ê°€ëœ ë¼ì¸ë§Œ ì¶”ì¶œ"""
        added_lines = []
        for line in patch.split('\n'):
            # +ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ (+++ëŠ” ì œì™¸)
            if line.startswith('+') and not line.startswith('+++'):
                added_lines.append(line[1:])  # + ê¸°í˜¸ ì œê±°
        return added_lines
    
    def _extract_removed_lines(self, patch: str) -> List[str]:
        """diffì—ì„œ ì œê±°ëœ ë¼ì¸ë§Œ ì¶”ì¶œ"""
        removed_lines = []
        for line in patch.split('\n'):
            # -ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ (---ëŠ” ì œì™¸)
            if line.startswith('-') and not line.startswith('---'):
                removed_lines.append(line[1:])  # - ê¸°í˜¸ ì œê±°
        return removed_lines
    
    def _extract_commit_info(self, commits: List[Dict]) -> List[Dict]:
        """ì»¤ë°‹ ì •ë³´ ì¶”ì¶œ"""
        commit_info = []
        for commit in commits[:10]:  # ìµœê·¼ 10ê°œë§Œ
            commit_info.append({
                "sha": commit["sha"][:7],
                "message": commit["commit"]["message"].split('\n')[0],  # ì²« ì¤„ë§Œ
                "author": commit["commit"]["author"]["name"],
                "date": commit["commit"]["author"]["date"]
            })
        return commit_info
    
    def _get_file_content(self, repo_url: str, branch: str, filepath: str) -> Optional[str]:
        """íŠ¹ì • ë¸Œëœì¹˜ì˜ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            owner, repo = self._parse_github_url(repo_url)
            if not owner or not repo:
                return None
            
            # GitHub APIë¡œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            encoded_path = urllib.parse.quote(filepath.lstrip('/'), safe='/')
            api_url = f"{self.api_base}/repos/{owner}/{repo}/contents/{encoded_path}"
            params = {"ref": branch}
            
            response = requests.get(api_url, headers=self.headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                # base64 ë””ì½”ë”©
                if data.get("encoding") == "base64":
                    content = base64.b64decode(data["content"]).decode('utf-8', errors='ignore')
                    return content
                # download_url í´ë°±
                download_url = data.get('download_url')
                if download_url:
                    raw = self._get_file_content_raw(download_url)
                    if raw is not None:
                        return raw
            else:
                # 404/403 ë“±ì¼ ë•Œ raw ê²½ë¡œ í´ë°±
                raw_url = f"https://raw.githubusercontent.com/{owner}/{repo}/{urllib.parse.quote(branch, safe='')}/{encoded_path}"
                raw = self._get_file_content_raw(raw_url)
                if raw is not None:
                    return raw
            
        except Exception as e:
            print(f"íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
        return None

    def _get_file_content_raw(self, raw_url: str) -> Optional[str]:
        """raw_urlë¡œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ëŒ€ìš©ëŸ‰/íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í´ë°±)"""
        try:
            # raw.githubusercontent.com ë„ë©”ì¸ì—ì„œë„ Authorization í—¤ë”ê°€ ë™ì‘í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´ ê·¸ëŒ€ë¡œ ì „ë‹¬
            resp = requests.get(raw_url, headers=self.headers)
            if resp.status_code == 200:
                return resp.text
        except Exception as e:
            print(f"raw_url ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None
    
    def _generate_pr_recommendation(self, security_result: Dict) -> str:
        """PR ë¨¸ì§€ ì¶”ì²œ ìƒì„±"""
        if not security_result.get("vulnerabilities"):
            return "âœ… ë³´ì•ˆ ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¸ì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        
        critical = sum(1 for v in security_result["vulnerabilities"] 
                      if v.get("severity") == "CRITICAL")
        high = sum(1 for v in security_result["vulnerabilities"] 
                  if v.get("severity") == "HIGH")
        
        if critical > 0:
            return f"ğŸš« {critical}ê°œì˜ ì‹¬ê°í•œ ë³´ì•ˆ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì • í›„ ë¨¸ì§€í•˜ì„¸ìš”."
        elif high > 0:
            return f"âš ï¸ {high}ê°œì˜ ë†’ì€ ìœ„í—˜ë„ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ ë¨¸ì§€í•˜ì„¸ìš”."
        else:
            return "âš ï¸ ê²½ë¯¸í•œ ë³´ì•ˆ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ ë¨¸ì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    def cleanup(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            try:
                shutil.rmtree(self.temp_dir)
            except:
                pass


class BranchDiffSelector:
    """ë¸Œëœì¹˜ diff íŒŒì¼ ì„ íƒ í—¬í¼"""
    
    @staticmethod
    def filter_by_status(files: List[Dict], statuses: List[str]) -> List[Dict]:
        """
        ìƒíƒœë³„ íŒŒì¼ í•„í„°ë§
        
        Args:
            files: íŒŒì¼ ëª©ë¡
            statuses: ["added", "modified", "removed"]
        """
        return [f for f in files if f.get("status") in statuses]
    
    @staticmethod
    def filter_by_size(files: List[Dict], max_changes: int = 500) -> List[Dict]:
        """ë³€ê²½ í¬ê¸°ë³„ í•„í„°ë§"""
        return [f for f in files if f.get("changes", 0) <= max_changes]
    
    @staticmethod
    def filter_by_pattern(files: List[Dict], patterns: List[str]) -> List[Dict]:
        """íŒŒì¼ íŒ¨í„´ë³„ í•„í„°ë§"""
        filtered = []
        for file in files:
            filename = file.get("filename", "")
            for pattern in patterns:
                if pattern in filename:
                    filtered.append(file)
                    break
        return filtered
    
    @staticmethod
    def get_security_critical_files(files: List[Dict]) -> List[Dict]:
        """ë³´ì•ˆìƒ ì¤‘ìš”í•œ íŒŒì¼ë§Œ ì„ íƒ"""
        critical_patterns = [
            'auth', 'login', 'security', 'password', 'token',
            'api', 'admin', 'config', 'settings', 'env',
            'database', 'db', 'sql', 'orm',
            'middleware', 'permission', 'role'
        ]
        
        critical_files = []
        for file in files:
            filename = file.get("filename", "").lower()
            for pattern in critical_patterns:
                if pattern in filename:
                    critical_files.append(file)
                    break
        
        return critical_files