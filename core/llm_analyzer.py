# core/llm_analyzer.py
"""
LLM ê¸°ë°˜ ì½”ë“œ ë³´ì•ˆ ë¶„ì„ ëª¨ë“ˆ - í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬ ë²„ì „
"""
from openai import OpenAI
import json
import os
from typing import Dict, List, Optional
from rag.simple_rag import SimpleRAG

# í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
try:
    from prompts.security_prompts import (
        SYSTEM_PROMPT,
        get_analysis_prompt,
        get_rag_prompt,
        translate_vulnerability_type,
        get_common_fix,
        SEVERITY_DESCRIPTIONS
    )
except ImportError:
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    SYSTEM_PROMPT = "You are a Python security expert. Respond with JSON only."
    def get_analysis_prompt(code): return f"Analyze this code:\n{code}"
    def translate_vulnerability_type(t): return t
    def get_common_fix(t): return {}
    SEVERITY_DESCRIPTIONS = {}

class LLMSecurityAnalyzer:
    """GPT ì¤‘ì‹¬ ë³´ì•ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
        
        # RAG ì‹œìŠ¤í…œ (ì„¤ëª… ë³´ê°•ìš©)
        try:
            self.rag = SimpleRAG()
            self.rag_available = True
        except:
            self.rag = None
            self.rag_available = False
            print("âš ï¸ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨ - GPT ì„¤ëª…ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    
    def analyze_code_security(self, code: str, context: Dict = None) -> Dict:
        """
        ì½”ë“œ ë³´ì•ˆ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ - ìµœì í™” ë²„ì „
        1. GPTê°€ ì·¨ì•½ì  íƒì§€
        2. ì„¤ëª…ê³¼ ìˆ˜ì •ì„ í•œ ë²ˆì— ìƒì„±
        """
        
        # 1ë‹¨ê³„: GPTë¡œ ì·¨ì•½ì  íƒì§€ + ìˆ˜ì •ê¹Œì§€ í•œë²ˆì—
        print("ğŸ” AI ë³´ì•ˆ ë¶„ì„ ì‹œì‘...")
        result = self._gpt_analyze_all_at_once(code)
        
        if not result or not result.get('vulnerabilities'):
            return {
                "success": True,
                "analysis": {
                    "code_vulnerabilities": [],
                    "security_score": 100,
                    "summary": "ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "immediate_actions": [],
                    "best_practices": ["í˜„ì¬ ì½”ë“œëŠ” ê¸°ë³¸ì ì¸ ë³´ì•ˆ ê¸°ì¤€ì„ ì¶©ì¡±í•©ë‹ˆë‹¤."]
                }
            }
        
        vulnerabilities = result['vulnerabilities']
        
        # 2ë‹¨ê³„: RAGë¡œ ì„¤ëª… ë³´ê°• (ì„ íƒì , ë¹ ë¥´ê²Œ)
        if self.rag_available:
            self._enhance_with_rag(vulnerabilities)
        
        # 3ë‹¨ê³„: ë³´ì•ˆ ì ìˆ˜ ë° ê¶Œì¥ì‚¬í•­
        security_score = self._calculate_security_score(vulnerabilities)
        immediate_actions = self._generate_immediate_actions(vulnerabilities)
        best_practices = self._generate_best_practices(vulnerabilities)
        
        return {
            "success": True,
            "analysis": {
                "code_vulnerabilities": vulnerabilities,
                "security_score": security_score,
                "summary": self._generate_summary(vulnerabilities),
                "immediate_actions": immediate_actions,
                "best_practices": best_practices
            },
            "metadata": {
                "gpt_model": self.model,
                "rag_available": self.rag_available,
                "total_vulnerabilities": len(vulnerabilities)
            }
        }
    
    def _gpt_analyze_all_at_once(self, code: str) -> Dict:
        """GPTë¡œ íƒì§€, ì„¤ëª…, ìˆ˜ì •ì„ í•œ ë²ˆì— ì²˜ë¦¬ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì‚¬ìš©)"""
        
        # ì½”ë“œì— ë¼ì¸ ë²ˆí˜¸ ì¶”ê°€
        lines = code.split('\n')
        code_with_lines = '\n'.join([f"{i+1:3}: {line}" for i, line in enumerate(lines)])
        
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        prompt = get_analysis_prompt(code_with_lines)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=2500
            )
            
            result_text = response.choices[0].message.content
            
            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]
            
            result = json.loads(result_text.strip())
            
            # í›„ì²˜ë¦¬: í•œê¸€ ë²ˆì—­ ë° ì„¤ëª… ê°œì„ 
            for vuln in result.get('vulnerabilities', []):
                # ì·¨ì•½ì  íƒ€ì… í•œê¸€ ì¶”ê°€
                if 'type' in vuln:
                    vuln['type_korean'] = translate_vulnerability_type(vuln['type'])
                
                # ì„¤ëª…ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ë³´ê°•
                if vuln.get('description', '') and len(vuln['description']) < 20:
                    common_fix = get_common_fix(vuln['type'])
                    if common_fix:
                        vuln['description'] = f"{vuln['description']}. {common_fix.get('pattern', '')}ì„ ì‚¬ìš©í•˜ë©´ ìœ„í—˜í•©ë‹ˆë‹¤."
                
                # ì˜í–¥ë„ ì„¤ëª… ì¶”ê°€
                if not vuln.get('impact'):
                    severity = vuln.get('severity', 'MEDIUM')
                    vuln['impact'] = SEVERITY_DESCRIPTIONS.get(severity, '')
                
                vuln['explanation_source'] = 'AI ë¶„ì„'
            
            return result
            
        except Exception as e:
            print(f"âŒ GPT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"vulnerabilities": []}
    
    def _enhance_with_rag(self, vulnerabilities: List[Dict]):
        """RAGë¡œ ì„¤ëª… ë³´ê°• - ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ"""
        
        if not self.rag_available:
            return
        
        # íƒ€ì…ë³„ë¡œ í•œ ë²ˆë§Œ ê²€ìƒ‰
        searched_types = {}
        
        for vuln in vulnerabilities[:5]:  # ìµœëŒ€ 5ê°œë§Œ RAG ê²€ìƒ‰
            vuln_type = vuln.get('type', '')
            
            if vuln_type not in searched_types:
                # RAG ê²€ìƒ‰ ë° ì •ì œ
                rag_result = self._search_and_refine_rag(vuln_type)
                if rag_result:
                    searched_types[vuln_type] = rag_result
            
            # RAG ì„¤ëª…ì´ ìˆìœ¼ë©´ ì¶”ê°€ (ëŒ€ì²´ê°€ ì•„ë‹Œ ë³´ê°•)
            if vuln_type in searched_types:
                # AI ì„¤ëª…ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                ai_description = vuln.get('description', '')
                rag_enhancement = searched_types[vuln_type]
                
                # RAG ì„¤ëª…ì„ ë³„ë„ í•„ë“œë¡œ ì €ì¥ (UIì—ì„œ êµ¬ë¶„ í‘œì‹œ)
                vuln['ai_description'] = ai_description
                vuln['rag_explanation'] = rag_enhancement
                vuln['explanation_source'] = 'AI ë¶„ì„ + KISIA ê°€ì´ë“œë¼ì¸'
                
                # ì „ì²´ ì„¤ëª…ì€ ê°„ê²°í•˜ê²Œ ìœ ì§€
                vuln['explanation'] = ai_description  # ê¸°ë³¸ì€ AI ì„¤ëª…ë§Œ
    
    def _search_and_refine_rag(self, vuln_type: str) -> Optional[str]:
        """RAG ê²€ìƒ‰ í›„ GPTë¡œ ì •ì œ - ê´€ë ¨ ë‚´ìš©ë§Œ ì¶”ì¶œ"""
        if not self.rag_available:
            return None
        
        try:
            # í•œê¸€ ë³€í™˜
            korean_type = translate_vulnerability_type(vuln_type)
            
            # ë” ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬
            search_queries = [
                f"{korean_type} ì·¨ì•½ì ",
                f"{korean_type} ê³µê²©",
                f"{korean_type} ë°©ì–´"
            ]
            
            relevant_docs = []
            for query in search_queries:
                results = self.rag.search_similar(query, top_k=1)
                if results['documents'][0]:
                    doc = results['documents'][0][0]
                    # ê´€ë ¨ì„± ì²´í¬ - í•´ë‹¹ ì·¨ì•½ì  í‚¤ì›Œë“œê°€ ìˆëŠ” ë¬¸ì„œë§Œ
                    if korean_type in doc or vuln_type.lower() in doc.lower():
                        relevant_docs.append(doc[:300])  # 300ìë§Œ
            
            if not relevant_docs:
                return None
            
            # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œ ì‚¬ìš©
            rag_context = relevant_docs[0] if relevant_docs else ""
            
            # GPTë¡œ ì •ì œ - ê´€ë ¨ ë‚´ìš©ë§Œ ì¶”ì¶œ
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ {korean_type} ì·¨ì•½ì ì— ëŒ€í•œ ì„¤ëª…ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

[í…ìŠ¤íŠ¸]
{rag_context}

[ìš”êµ¬ì‚¬í•­]
- {korean_type}ì— ëŒ€í•œ ë‚´ìš©ë§Œ ì¶”ì¶œ
- ë‹¤ë¥¸ ì·¨ì•½ì  ì„¤ëª… ì œì™¸
- ìµœëŒ€ 2ë¬¸ì¥, 100ì ì´ë‚´
- í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ

ì„¤ëª…:"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë³´ì•ˆ ì „ë¬¸ê°€. ìš”ì²­ëœ ì·¨ì•½ì  ì •ë³´ë§Œ ì •í™•íˆ ì¶”ì¶œ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ë” ì •í™•í•œ ì¶”ì¶œì„ ìœ„í•´ ë‚®ì¶¤
                max_tokens=150
            )
            
            refined_explanation = response.choices[0].message.content.strip()
            
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì´ë©´ ë¬´ì‹œ
            if len(refined_explanation) < 20 or korean_type not in refined_explanation:
                return None
                
            return refined_explanation
                
        except Exception as e:
            print(f"RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None
    
    def _gpt_detect_vulnerabilities(self, code: str) -> List[Dict]:
        """GPTë¥¼ ì‚¬ìš©í•œ ì·¨ì•½ì  íƒì§€ (ë©”ì¸ ì—”ì§„)"""
        
        # ì½”ë“œì— ë¼ì¸ ë²ˆí˜¸ ì¶”ê°€
        lines = code.split('\n')
        code_with_lines = '\n'.join([f"{i+1:3}: {line}" for i, line in enumerate(lines)])
        
        prompt = f"""
        ë‹¹ì‹ ì€ Python ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë³´ì•ˆ ì·¨ì•½ì ì„ ì°¾ì•„ì£¼ì„¸ìš”.
        
        [ë¶„ì„í•  ì½”ë“œ]
        ```python
        {code_with_lines}
        ```
        
        ë‹¤ìŒê³¼ ê°™ì€ ì·¨ì•½ì ì„ ì¤‘ì ì ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”:
        1. ì¸ì ì…˜ ê³µê²© (SQL, Command, Code, Path ë“±)
        2. ì¸ì¦/ì¸ê°€ ë¬¸ì œ
        3. ì•”í˜¸í™” ê´€ë ¨ ë¬¸ì œ (ì•½í•œ ì•Œê³ ë¦¬ì¦˜, í•˜ë“œì½”ë”©ëœ í‚¤)
        4. ì…ë ¥ê°’ ê²€ì¦ ë¶€ì¬
        5. ë¯¼ê° ì •ë³´ ë…¸ì¶œ
        6. ì•ˆì „í•˜ì§€ ì•Šì€ ì—­ì§ë ¬í™”
        7. XXE, XSS, CSRF ë“± ì›¹ ì·¨ì•½ì 
        8. ê²½ìŸ ì¡°ê±´, ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ë¬¸ì œ
        9. ì—ëŸ¬ ì²˜ë¦¬ ë¯¸í¡
        10. ê¸°íƒ€ ë³´ì•ˆ ë¬¸ì œ
        
        ê° ì·¨ì•½ì ì— ëŒ€í•´ ì •í™•í•œ ë¼ì¸ ë²ˆí˜¸ë¥¼ í¬í•¨í•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        {{
            "vulnerabilities": [
                {{
                    "type": "ì·¨ì•½ì  ì¢…ë¥˜ (ì˜ˆ: SQL Injection)",
                    "severity": "CRITICAL/HIGH/MEDIUM/LOW",
                    "line_numbers": [ë¼ì¸ë²ˆí˜¸ë“¤],
                    "vulnerable_code": "ì·¨ì•½í•œ ì½”ë“œ ë¶€ë¶„",
                    "description": "ì·¨ì•½ì ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…",
                    "cwe_id": "CWE-XX (í•´ë‹¹í•˜ëŠ” ê²½ìš°)",
                    "confidence": "HIGH/MEDIUM/LOW (íƒì§€ í™•ì‹ ë„)"
                }}
            ]
        }}
        
        ì·¨ì•½ì ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.
        ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "You are a security expert specializing in Python code analysis. Always respond with valid JSON."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
                max_tokens=2000
            )
            
            result_text = response.choices[0].message.content
            
            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]
            
            result = json.loads(result_text.strip())
            return result.get("vulnerabilities", [])
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
        except Exception as e:
            print(f"âŒ GPT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return []
    
    def _add_explanations(self, vulnerabilities: List[Dict], code: str) -> List[Dict]:
        """ê° ì·¨ì•½ì ì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€ - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ ê°œì„ """
        
        if not vulnerabilities:
            return vulnerabilities
        
        # RAG ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ë¨¼ì € ì¼ê´„ ê²€ìƒ‰
        rag_explanations = {}
        if self.rag_available:
            print(f"ğŸ“š RAGì—ì„œ {len(vulnerabilities)}ê°œ ì·¨ì•½ì  ì„¤ëª… ê²€ìƒ‰...")
            for vuln in vulnerabilities:
                vuln_type = vuln.get('type', '')
                if vuln_type not in rag_explanations:
                    rag_explanations[vuln_type] = self._search_rag_explanation(vuln_type)
        
        # ë°°ì¹˜ë¡œ ìˆ˜ì • ì½”ë“œ ìƒì„± (í•œ ë²ˆì˜ GPT í˜¸ì¶œë¡œ ëª¨ë“  ìˆ˜ì • ìƒì„±)
        if len(vulnerabilities) <= 3:
            # 3ê°œ ì´í•˜ë©´ ê°œë³„ ì²˜ë¦¬ (ë” ì •í™•)
            for vuln in vulnerabilities:
                vuln_type = vuln.get('type', '')
                
                # RAG ì„¤ëª… ì‚¬ìš© ë˜ëŠ” GPT ìƒì„±
                if vuln_type in rag_explanations and rag_explanations[vuln_type]:
                    vuln['explanation'] = rag_explanations[vuln_type]
                    vuln['explanation_source'] = 'KISIA ê°€ì´ë“œë¼ì¸'
                else:
                    vuln['explanation'] = self._gpt_generate_explanation(vuln)
                    vuln['explanation_source'] = 'AI ìƒì„±'
                
                # ìˆ˜ì • ì½”ë“œ ìƒì„±
                vuln['recommended_fix'] = self._gpt_generate_fix(vuln, code)
        else:
            # 4ê°œ ì´ìƒì´ë©´ ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)
            print(f"âš¡ {len(vulnerabilities)}ê°œ ì·¨ì•½ì  ë°°ì¹˜ ì²˜ë¦¬...")
            
            # ì„¤ëª…ì€ RAG ë˜ëŠ” ê°„ë‹¨ ìƒì„±
            for vuln in vulnerabilities:
                vuln_type = vuln.get('type', '')
                if vuln_type in rag_explanations and rag_explanations[vuln_type]:
                    vuln['explanation'] = rag_explanations[vuln_type]
                    vuln['explanation_source'] = 'KISIA ê°€ì´ë“œë¼ì¸'
                else:
                    vuln['explanation'] = vuln.get('description', '')  # ê¸°ë³¸ ì„¤ëª… ì‚¬ìš©
                    vuln['explanation_source'] = 'AI ìƒì„±'
            
            # ìˆ˜ì • ì½”ë“œëŠ” ë°°ì¹˜ë¡œ ìƒì„±
            fixes = self._batch_generate_fixes(vulnerabilities, code)
            for i, vuln in enumerate(vulnerabilities):
                vuln['recommended_fix'] = fixes[i] if i < len(fixes) else None
        
        return vulnerabilities
    
    def _batch_generate_fixes(self, vulnerabilities: List[Dict], code: str) -> List[Dict]:
        """ì—¬ëŸ¬ ì·¨ì•½ì ì˜ ìˆ˜ì • ì½”ë“œë¥¼ í•œ ë²ˆì— ìƒì„± (ì†ë„ ê°œì„ )"""
        
        # ì·¨ì•½ì  ìš”ì•½
        vuln_summary = []
        for i, vuln in enumerate(vulnerabilities[:10]):  # ìµœëŒ€ 10ê°œë§Œ
            vuln_summary.append(f"{i+1}. {vuln['type']} (ë¼ì¸ {vuln.get('line_numbers', ['?'])[0]}): {vuln.get('vulnerable_code', '')[:50]}")
        
        prompt = f"""
        ë‹¤ìŒ Python ì½”ë“œì˜ ì—¬ëŸ¬ ì·¨ì•½ì ì„ ìˆ˜ì •í•˜ì„¸ìš”.
        
        ì·¨ì•½ì  ëª©ë¡:
        {chr(10).join(vuln_summary)}
        
        ê° ì·¨ì•½ì ì— ëŒ€í•´ ê°„ë‹¨í•œ ìˆ˜ì • ì½”ë“œë¥¼ ì œì‹œí•˜ì„¸ìš”.
        JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
        [
            {{
                "original_code": "ì·¨ì•½í•œ ì½”ë“œ",
                "fixed_code": "ìˆ˜ì •ëœ ì½”ë“œ",
                "description": "ë³€ê²½ ì„¤ëª…"
            }},
            ...
        ]
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Python ë³´ì•ˆ ì „ë¬¸ê°€. ê°„ê²°í•œ ìˆ˜ì • ì½”ë“œ ì œê³µ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            result_text = response.choices[0].message.content
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            
            fixes = json.loads(result_text.strip())
            
            # Dict í˜•íƒœë¡œ ë³€í™˜
            return [
                {
                    "original_code": fix.get("original_code", ""),
                    "fixed_code": fix.get("fixed_code", ""),
                    "description": fix.get("description", ""),
                    "imports": [],
                    "confidence": 0.7
                }
                for fix in fixes
            ]
            
        except Exception as e:
            print(f"ë°°ì¹˜ ìˆ˜ì • ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ ë¹ˆ ìˆ˜ì • ë°˜í™˜
            return [{"fixed_code": "# ìë™ ìˆ˜ì • ì‹¤íŒ¨", "description": "ìˆ˜ë™ ìˆ˜ì • í•„ìš”"} for _ in vulnerabilities]
    
    def _search_rag_explanation(self, vuln_type: str) -> Optional[str]:
        """RAGì—ì„œ ì·¨ì•½ì  ì„¤ëª… ê²€ìƒ‰í•˜ê³  GPTë¡œ ì •ì œ"""
        if not self.rag_available:
            return None
        
        # ì·¨ì•½ì  íƒ€ì…ì„ í•œê¸€ë¡œ ë§¤í•‘
        type_mapping = {
            'SQL Injection': 'SQL ì‚½ì…',
            'Command Injection': 'ëª…ë ¹ì–´ ì‚½ì…',
            'Path Traversal': 'ê²½ë¡œ ì¡°ì‘',
            'XSS': 'í¬ë¡œìŠ¤ì‚¬ì´íŠ¸ ìŠ¤í¬ë¦½íŒ…',
            'Weak Cryptography': 'ì·¨ì•½í•œ ì•”í˜¸í™”',
            'Hardcoded Secret': 'í•˜ë“œì½”ë”©ëœ íŒ¨ìŠ¤ì›Œë“œ',
            'Insecure Deserialization': 'ì•ˆì „í•˜ì§€ ì•Šì€ ì—­ì§ë ¬í™”'
        }
        
        korean_type = type_mapping.get(vuln_type, vuln_type)
        search_query = f"{korean_type} ì·¨ì•½ì  ë³´ì•ˆì•½ì "
        
        try:
            results = self.rag.search_similar(search_query, top_k=2)
            if results['documents'][0]:
                # RAG ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                rag_context = '\n'.join(results['documents'][0][:2])
                
                # GPTê°€ RAG ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì„¤ëª…
                prompt = f"""
                KISIA Python ì‹œíì–´ì½”ë”© ê°€ì´ë“œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {vuln_type} ì·¨ì•½ì ì„ ì„¤ëª…í•˜ì„¸ìš”.
                
                [ê°€ì´ë“œë¼ì¸ ë‚´ìš©]
                {rag_context}
                
                ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒì„ í¬í•¨í•´ 150ì ì´ë‚´ë¡œ ê¹”ë”í•˜ê²Œ ì„¤ëª…:
                1. ì·¨ì•½ì ì´ ë¬´ì—‡ì¸ì§€
                2. ì™œ ìœ„í—˜í•œì§€
                3. í•µì‹¬ ë°©ì–´ ë°©ë²•
                
                í˜ì´ì§€ ë²ˆí˜¸ë‚˜ ì½”ë“œ ë¼ì¸ ë²ˆí˜¸ëŠ” ì œì™¸í•˜ê³  ì„¤ëª…ë§Œ ì‘ì„±í•˜ì„¸ìš”.
                """
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "KISIA ì‹œíì–´ì½”ë”© ê°€ì´ë“œ ì „ë¬¸ê°€. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=300
                )
                
                return response.choices[0].message.content.strip()
        except:
            pass
        
        return None
    
    def _search_rag_fix(self, vuln_type: str) -> Optional[str]:
        """RAGì—ì„œ ìˆ˜ì • ë°©ë²• ê²€ìƒ‰í•˜ê³  GPTë¡œ ì •ì œ"""
        if not self.rag_available:
            return None
        
        search_query = f"{vuln_type} ì•ˆì „í•œ ì½”ë“œ ìˆ˜ì • ë°©ë²•"
        
        try:
            results = self.rag.search_similar(search_query, top_k=2)
            if results['documents'][0]:
                rag_context = '\n'.join(results['documents'][0][:2])
                
                # GPTê°€ RAG ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ìˆ˜ì • ë°©ë²• ì œì‹œ
                prompt = f"""
                KISIA ê°€ì´ë“œë¼ì¸ì„ ë°”íƒ•ìœ¼ë¡œ {vuln_type} ì·¨ì•½ì ì˜ ìˆ˜ì • ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”.
                
                [ê°€ì´ë“œë¼ì¸ ì°¸ê³  ë‚´ìš©]
                {rag_context}
                
                ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‹¤ì œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì • ë°©ë²•ì„ 3ì¤„ ì´ë‚´ë¡œ ì œì‹œ:
                1. êµ¬ì²´ì ì¸ íŒŒì´ì¬ ì½”ë“œë‚˜ í•¨ìˆ˜ëª… ì–¸ê¸‰
                2. ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ í•´ê²°ì±…
                
                ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ í•µì‹¬ í•´ê²° ë°©ë²•ë§Œ ì œì‹œí•˜ì„¸ìš”.
                """
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "Python ë³´ì•ˆ ì „ë¬¸ê°€. ì‹¤ìš©ì ì¸ ì½”ë“œ ìˆ˜ì • ë°©ë²• ì œì‹œ."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=200
                )
                
                return response.choices[0].message.content.strip()
        except:
            pass
        
        return None
    
    def _gpt_generate_explanation(self, vuln: Dict) -> str:
        """GPTë¡œ ì·¨ì•½ì  ì„¤ëª… ìƒì„±"""
        prompt = f"""
        ë‹¤ìŒ ë³´ì•ˆ ì·¨ì•½ì ì— ëŒ€í•´ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”:
        - ì¢…ë¥˜: {vuln['type']}
        - ì„¤ëª…: {vuln['description']}
        
        100ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ì„¤ëª…í•˜ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë³´ì•ˆ ì „ë¬¸ê°€ë¡œì„œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            return response.choices[0].message.content.strip()
        except:
            return vuln.get('description', 'ì„¤ëª… ìƒì„± ì‹¤íŒ¨')
    
    def _gpt_generate_fix(self, vuln: Dict, code: str) -> Dict:
        """GPTë¡œ ì‹¤ì œ ìˆ˜ì • ì½”ë“œ ìƒì„±"""
        vulnerable_code = vuln.get('vulnerable_code', '')
        line_numbers = vuln.get('line_numbers', [])
        
        # ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì·¨ì•½í•œ ë¼ì¸ ì „í›„ í¬í•¨)
        code_lines = code.split('\n')
        context_start = max(0, line_numbers[0] - 3) if line_numbers else 0
        context_end = min(len(code_lines), line_numbers[0] + 2) if line_numbers else len(code_lines)
        code_context = '\n'.join(code_lines[context_start:context_end])
        
        prompt = f"""
        ë‹¤ìŒ Python ì½”ë“œì˜ ë³´ì•ˆ ì·¨ì•½ì ì„ ìˆ˜ì •í•˜ì„¸ìš”.
        
        ì·¨ì•½ì  ì¢…ë¥˜: {vuln['type']}
        ì·¨ì•½í•œ ì½”ë“œ ë¼ì¸: {vulnerable_code}
        
        ì½”ë“œ ì»¨í…ìŠ¤íŠ¸:
        ```python
        {code_context}
        ```
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
        {{
            "original_code": "ì·¨ì•½í•œ ì›ë³¸ ì½”ë“œ (í•´ë‹¹ ë¼ì¸ë§Œ)",
            "fixed_code": "ìˆ˜ì •ëœ ì½”ë“œ (ë™ì¼í•œ ê¸°ëŠ¥ ìœ ì§€)",
            "changes_description": "ë¬´ì—‡ì„ ì–´ë–»ê²Œ ë°”ê¿¨ëŠ”ì§€ ê°„ë‹¨ ì„¤ëª…",
            "additional_imports": ["í•„ìš”í•œ ì¶”ê°€ import ë¬¸"],
            "confidence": 0.0-1.0
        }}
        
        ì¤‘ìš”: 
        - ì›ë³¸ ê¸°ëŠ¥ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ ë³´ì•ˆ ì·¨ì•½ì ë§Œ ìˆ˜ì •
        - ì‹¤ì œë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì œê³µ
        - í•„ìš”í•œ import ë¬¸ë„ ëª…ì‹œ
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Python ë³´ì•ˆ ì „ë¬¸ê°€. ì‹¤ì œ ë™ì‘í•˜ëŠ” ìˆ˜ì • ì½”ë“œë¥¼ JSONìœ¼ë¡œ ì œê³µ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content
            
            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]
            
            import json
            fix_data = json.loads(result_text.strip())
            
            return {
                "original_code": fix_data.get("original_code", vulnerable_code),
                "fixed_code": fix_data.get("fixed_code", "# ìˆ˜ì • ì½”ë“œ ìƒì„± ì‹¤íŒ¨"),
                "description": fix_data.get("changes_description", ""),
                "imports": fix_data.get("additional_imports", []),
                "confidence": fix_data.get("confidence", 0.5)
            }
            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì œì•ˆ
            return {
                "original_code": vulnerable_code,
                "fixed_code": "# ìë™ ìˆ˜ì • ì‹¤íŒ¨ - ìˆ˜ë™ ìˆ˜ì • í•„ìš”",
                "description": f"ìˆ˜ì • ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "imports": [],
                "confidence": 0.0
            }
    
    def _calculate_security_score(self, vulnerabilities: List[Dict]) -> int:
        """ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 100
        
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'MEDIUM')
            confidence = vuln.get('confidence', 'MEDIUM')
            
            # ì‹¬ê°ë„ë³„ ê°ì 
            severity_penalty = {
                'CRITICAL': 25,
                'HIGH': 15,
                'MEDIUM': 10,
                'LOW': 5
            }.get(severity, 10)
            
            # í™•ì‹ ë„ì— ë”°ë¥¸ ì¡°ì •
            if confidence == 'LOW':
                severity_penalty = severity_penalty * 0.5
            elif confidence == 'HIGH':
                severity_penalty = severity_penalty * 1.2
            
            score -= severity_penalty
        
        return max(0, int(score))
    
    def _generate_immediate_actions(self, vulnerabilities: List[Dict]) -> List[str]:
        """ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­ ìƒì„±"""
        actions = []
        
        # CRITICAL/HIGH ìš°ì„ 
        critical_vulns = [v for v in vulnerabilities if v.get('severity') in ['CRITICAL', 'HIGH']]
        
        for vuln in critical_vulns[:5]:  # ìµœëŒ€ 5ê°œ
            line = vuln.get('line_numbers', [0])[0]
            actions.append(f"ë¼ì¸ {line}: {vuln['type']} ì¦‰ì‹œ ìˆ˜ì • í•„ìš”")
        
        if not actions:
            actions.append("ì‹¬ê°í•œ ì·¨ì•½ì ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ì „ì²´ ì·¨ì•½ì ì„ ê²€í† í•˜ì„¸ìš”.")
        
        return actions
    
    def _generate_best_practices(self, vulnerabilities: List[Dict]) -> List[str]:
        """ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€ ìƒì„±"""
        practices = set()
        
        for vuln in vulnerabilities:
            vuln_type = vuln.get('type', '')
            
            if 'Injection' in vuln_type:
                practices.add("ëª¨ë“  ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•´ íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©")
            elif 'Cryptography' in vuln_type:
                practices.add("ê°•ë ¥í•œ ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© (AES-256, SHA-256 ì´ìƒ)")
            elif 'Secret' in vuln_type or 'Password' in vuln_type:
                practices.add("ë¯¼ê°í•œ ì •ë³´ëŠ” í™˜ê²½ ë³€ìˆ˜ë‚˜ ë³´ì•ˆ ì €ì¥ì†Œì— ë³´ê´€")
            elif 'Validation' in vuln_type:
                practices.add("ëª¨ë“  ì…ë ¥ê°’ì— ëŒ€í•œ ê²€ì¦ ë° sanitization ìˆ˜í–‰")
        
        if not practices:
            practices.add("ì •ê¸°ì ì¸ ë³´ì•ˆ ê°ì‚¬ ì‹¤ì‹œ")
            practices.add("ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì •ê¸° ì—…ë°ì´íŠ¸")
        
        return list(practices)
    
    def _generate_summary(self, vulnerabilities: List[Dict]) -> str:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""
        if not vulnerabilities:
            return "ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        total = len(vulnerabilities)
        critical = len([v for v in vulnerabilities if v.get('severity') == 'CRITICAL'])
        high = len([v for v in vulnerabilities if v.get('severity') == 'HIGH'])
        
        summary = f"ì´ {total}ê°œì˜ ë³´ì•ˆ ì·¨ì•½ì  ë°œê²¬"
        if critical > 0:
            summary += f" (CRITICAL: {critical}ê°œ)"
        if high > 0:
            summary += f" (HIGH: {high}ê°œ)"
        
        return summary