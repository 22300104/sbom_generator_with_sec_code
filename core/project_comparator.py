"""
í”„ë¡œì íŠ¸ ë¹„êµ ë¶„ì„ ëª¨ë“ˆ
ì—¬ëŸ¬ í”„ë¡œì íŠ¸ì˜ ë³´ì•ˆ ìˆ˜ì¤€ì„ ë¹„êµ
"""
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import hashlib
from pathlib import Path


class ProjectComparator:
    """í”„ë¡œì íŠ¸ ê°„ ë³´ì•ˆ ìˆ˜ì¤€ ë¹„êµ"""
    
    def __init__(self):
        self.projects = {}
        self.comparison_results = {}
    
    def add_project(self, name: str, analysis_results: Dict, metadata: Dict = None):
        """ë¹„êµí•  í”„ë¡œì íŠ¸ ì¶”ê°€"""
        project_id = hashlib.md5(name.encode()).hexdigest()[:8]
        
        self.projects[project_id] = {
            'name': name,
            'analyzed_at': datetime.now().isoformat(),
            'metadata': metadata or {},
            'results': analysis_results,
            'metrics': self._calculate_metrics(analysis_results)
        }
        
        return project_id
    
    def _calculate_metrics(self, results: Dict) -> Dict:
        """í”„ë¡œì íŠ¸ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {
            'security_score': 0,
            'vulnerabilities': {
                'total': 0,
                'critical': 0,
                'high': 0,
                'medium': 0,
                'low': 0
            },
            'dependencies': {
                'total': 0,
                'vulnerable': 0,
                'outdated': 0
            },
            'code_quality': {
                'lines': 0,
                'files': 0,
                'test_coverage': False,
                'documentation': False
            },
            'compliance': {
                'has_security_policy': False,
                'has_dependency_check': False,
                'uses_secure_defaults': False
            }
        }
        
        # ë³´ì•ˆ ì ìˆ˜
        if 'security' in results:
            metrics['security_score'] = results['security'].get('security_score', 0)
            
            # ì·¨ì•½ì  ì¹´ìš´íŠ¸
            vulns = results['security'].get('code_vulnerabilities', [])
            metrics['vulnerabilities']['total'] = len(vulns)
            
            for vuln in vulns:
                severity = vuln.get('severity', 'MEDIUM').lower()
                if severity in metrics['vulnerabilities']:
                    metrics['vulnerabilities'][severity] += 1
        
        # ì˜ì¡´ì„± ë©”íŠ¸ë¦­
        if 'dependencies' in results:
            deps = results['dependencies']
            metrics['dependencies']['total'] = deps.get('summary', {}).get('external_packages', 0)
        
        # ì•Œë ¤ì§„ ì·¨ì•½ì 
        if 'vulnerabilities' in results:
            vuln_stats = results['vulnerabilities'].get('statistics', {})
            metrics['dependencies']['vulnerable'] = len(
                results['vulnerabilities'].get('direct_vulnerabilities', {})
            )
        
        # ì½”ë“œ í’ˆì§ˆ
        if 'project_data' in results:
            stats = results['project_data'].get('statistics', {})
            metrics['code_quality']['lines'] = stats.get('total_lines', 0)
            metrics['code_quality']['files'] = stats.get('total_files', 0)
        
        # êµ¬ì¡° ë¶„ì„
        if 'structure' in results:
            patterns = results['structure'].get('patterns', [])
            metrics['code_quality']['test_coverage'] = any('í…ŒìŠ¤íŠ¸' in p for p in patterns)
            metrics['compliance']['has_security_policy'] = any('ì¸ì¦' in p or 'ë¯¸ë“¤ì›¨ì–´' in p for p in patterns)
        
        return metrics
    
    def compare_projects(self, project_ids: List[str] = None) -> Dict:
        """í”„ë¡œì íŠ¸ë“¤ ë¹„êµ"""
        
        if not project_ids:
            project_ids = list(self.projects.keys())
        
        if len(project_ids) < 2:
            return {'error': 'ë¹„êµí•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ í”„ë¡œì íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤'}
        
        comparison = {
            'projects': [],
            'rankings': {},
            'insights': [],
            'recommendations': []
        }
        
        # ê° í”„ë¡œì íŠ¸ ì •ë³´ ìˆ˜ì§‘
        for pid in project_ids:
            if pid in self.projects:
                project = self.projects[pid]
                comparison['projects'].append({
                    'id': pid,
                    'name': project['name'],
                    'metrics': project['metrics']
                })
        
        # ë­í‚¹ ê³„ì‚°
        comparison['rankings'] = self._calculate_rankings(comparison['projects'])
        
        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        comparison['insights'] = self._generate_insights(comparison['projects'])
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        comparison['recommendations'] = self._generate_recommendations(comparison['projects'])
        
        self.comparison_results = comparison
        return comparison
    
    def _calculate_rankings(self, projects: List[Dict]) -> Dict:
        """ê° ë©”íŠ¸ë¦­ë³„ ìˆœìœ„ ê³„ì‚°"""
        rankings = {
            'security_score': [],
            'vulnerability_count': [],
            'dependency_health': [],
            'code_quality': [],
            'overall': []
        }
        
        # ë³´ì•ˆ ì ìˆ˜ ìˆœìœ„
        projects_sorted = sorted(
            projects, 
            key=lambda x: x['metrics']['security_score'], 
            reverse=True
        )
        rankings['security_score'] = [
            {'name': p['name'], 'score': p['metrics']['security_score']} 
            for p in projects_sorted
        ]
        
        # ì·¨ì•½ì  ìˆ˜ ìˆœìœ„ (ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
        projects_sorted = sorted(
            projects, 
            key=lambda x: x['metrics']['vulnerabilities']['total']
        )
        rankings['vulnerability_count'] = [
            {'name': p['name'], 'count': p['metrics']['vulnerabilities']['total']} 
            for p in projects_sorted
        ]
        
        # ì˜ì¡´ì„± ê±´ê°•ë„
        for project in projects:
            total_deps = project['metrics']['dependencies']['total']
            vulnerable_deps = project['metrics']['dependencies']['vulnerable']
            health_score = 100 - (vulnerable_deps / max(total_deps, 1) * 100) if total_deps > 0 else 100
            project['dependency_health'] = health_score
        
        projects_sorted = sorted(
            projects, 
            key=lambda x: x.get('dependency_health', 0) if x.get('dependency_health') is not None else 0, 
            reverse=True
        )
        rankings['dependency_health'] = [
            {
                'name': p['name'], 
                'health': f"{p.get('dependency_health', 0):.1f}%" if p.get('dependency_health') is not None else "N/A"
            } 
            for p in projects_sorted
        ]
        
        # ì „ì²´ ìˆœìœ„ (ê°€ì¤‘ í‰ê· )
        for project in projects:
            dep_health = project.get('dependency_health', 0) if project.get('dependency_health') is not None else 0
            overall_score = (
                project['metrics']['security_score'] * 0.4 +
                (100 - min(project['metrics']['vulnerabilities']['total'] * 5, 100)) * 0.3 +
                dep_health * 0.2 +
                (10 if project['metrics']['code_quality']['test_coverage'] else 0)
            )
            project['overall_score'] = overall_score
        
        projects_sorted = sorted(
            projects, 
            key=lambda x: x.get('overall_score', 0) if x.get('overall_score') is not None else 0, 
            reverse=True
        )
        rankings['overall'] = [
            {
                'name': p['name'], 
                'score': f"{p.get('overall_score', 0):.1f}" if p.get('overall_score') is not None else "0.0"
            } 
            for p in projects_sorted
        ]
        
        return rankings
    
    def _generate_insights(self, projects: List[Dict]) -> List[str]:
        """ë¹„êµ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ìµœê³ /ìµœì € ë³´ì•ˆ ì ìˆ˜
        scores = [p['metrics']['security_score'] for p in projects]
        if scores:
            best = max(scores)
            worst = min(scores)
            best_project = next(p for p in projects if p['metrics']['security_score'] == best)
            worst_project = next(p for p in projects if p['metrics']['security_score'] == worst)
            
            insights.append(
                f"ğŸ† {best_project['name']}ì´(ê°€) ê°€ì¥ ë†’ì€ ë³´ì•ˆ ì ìˆ˜({best}/100)ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤."
            )
            
            if best != worst:
                insights.append(
                    f"âš ï¸ {worst_project['name']}ì€(ëŠ”) ë³´ì•ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì ìˆ˜: {worst}/100)."
                )
        
        # ì·¨ì•½ì  ë¶„ì„
        total_vulns = sum(p['metrics']['vulnerabilities']['total'] for p in projects)
        critical_vulns = sum(p['metrics']['vulnerabilities']['critical'] for p in projects)
        
        if total_vulns > 0:
            insights.append(f"ğŸ“Š ì „ì²´ í”„ë¡œì íŠ¸ì—ì„œ ì´ {total_vulns}ê°œì˜ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            if critical_vulns > 0:
                insights.append(f"ğŸš¨ {critical_vulns}ê°œì˜ ì¹˜ëª…ì  ì·¨ì•½ì ì´ ì¦‰ì‹œ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì˜ì¡´ì„± ë¶„ì„
        total_deps = sum(p['metrics']['dependencies']['total'] for p in projects)
        vulnerable_deps = sum(p['metrics']['dependencies']['vulnerable'] for p in projects)
        
        if vulnerable_deps > 0 and total_deps > 0:
            vuln_ratio = (vulnerable_deps / total_deps) * 100
            insights.append(
                f"ğŸ“¦ ì „ì²´ ì˜ì¡´ì„±ì˜ {vuln_ratio:.1f}%ì—ì„œ ì•Œë ¤ì§„ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        
        # í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
        with_tests = sum(1 for p in projects if p['metrics']['code_quality']['test_coverage'])
        if with_tests < len(projects):
            insights.append(
                f"ğŸ§ª {len(projects) - with_tests}ê°œ í”„ë¡œì íŠ¸ì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤."
            )
        
        return insights
    
    def _generate_recommendations(self, projects: List[Dict]) -> List[Dict]:
        """í”„ë¡œì íŠ¸ë³„ ê°œì„  ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        for project in projects:
            project_recs = {
                'name': project['name'],
                'priority_actions': [],
                'improvements': []
            }
            
            metrics = project['metrics']
            
            # ìš°ì„  ì¡°ì¹˜ì‚¬í•­
            if metrics['vulnerabilities']['critical'] > 0:
                project_recs['priority_actions'].append(
                    f"ğŸ”´ {metrics['vulnerabilities']['critical']}ê°œì˜ ì¹˜ëª…ì  ì·¨ì•½ì  ì¦‰ì‹œ ìˆ˜ì •"
                )
            
            if metrics['vulnerabilities']['high'] > 0:
                project_recs['priority_actions'].append(
                    f"ğŸŸ  {metrics['vulnerabilities']['high']}ê°œì˜ ë†’ì€ ìœ„í—˜ ì·¨ì•½ì  ìˆ˜ì •"
                )
            
            if metrics['dependencies']['vulnerable'] > 0:
                project_recs['priority_actions'].append(
                    f"ğŸ“¦ {metrics['dependencies']['vulnerable']}ê°œì˜ ì·¨ì•½í•œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸"
                )
            
            # ê°œì„ ì‚¬í•­
            if metrics['security_score'] < 70:
                project_recs['improvements'].append("ë³´ì•ˆ ì½”ë“œ ë¦¬ë·° ì‹¤ì‹œ")
            
            if not metrics['code_quality']['test_coverage']:
                project_recs['improvements'].append("ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì¶”ê°€")
            
            if not metrics['compliance']['has_security_policy']:
                project_recs['improvements'].append("ë³´ì•ˆ ì •ì±… ë° ì¸ì¦ ëª¨ë“ˆ êµ¬í˜„")
            
            if metrics['dependencies']['total'] > 50:
                project_recs['improvements'].append("ì˜ì¡´ì„± ìµœì†Œí™” ê²€í† ")
            
            recommendations.append(project_recs)
        
        return recommendations
    
    def generate_comparison_report(self) -> str:
        """ë¹„êµ ë³´ê³ ì„œ ìƒì„±"""
        if not self.comparison_results:
            return "ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = []
        report.append("# í”„ë¡œì íŠ¸ ë³´ì•ˆ ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ\n")
        report.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # í”„ë¡œì íŠ¸ ëª©ë¡
        report.append("## ë¶„ì„ ëŒ€ìƒ í”„ë¡œì íŠ¸\n")
        for project in self.comparison_results['projects']:
            report.append(f"- {project['name']}\n")
        report.append("\n")
        
        # ìˆœìœ„
        report.append("## í”„ë¡œì íŠ¸ ìˆœìœ„\n\n")
        
        rankings = self.comparison_results['rankings']
        
        report.append("### ğŸ† ì „ì²´ ìˆœìœ„\n")
        for i, item in enumerate(rankings['overall'], 1):
            report.append(f"{i}. {item['name']} (ì ìˆ˜: {item['score']})\n")
        report.append("\n")
        
        report.append("### ğŸ“Š ë³´ì•ˆ ì ìˆ˜\n")
        for item in rankings['security_score']:
            report.append(f"- {item['name']}: {item['score']}/100\n")
        report.append("\n")
        
        report.append("### ğŸ›¡ï¸ ì·¨ì•½ì  ìˆ˜ (ì ì„ìˆ˜ë¡ ì¢‹ìŒ)\n")
        for item in rankings['vulnerability_count']:
            report.append(f"- {item['name']}: {item['count']}ê°œ\n")
        report.append("\n")
        
        # ì¸ì‚¬ì´íŠ¸
        report.append("## ì£¼ìš” ë°œê²¬ì‚¬í•­\n")
        for insight in self.comparison_results['insights']:
            report.append(f"- {insight}\n")
        report.append("\n")
        
        # ê¶Œì¥ì‚¬í•­
        report.append("## í”„ë¡œì íŠ¸ë³„ ê¶Œì¥ì‚¬í•­\n")
        for rec in self.comparison_results['recommendations']:
            report.append(f"\n### {rec['name']}\n")
            
            if rec['priority_actions']:
                report.append("**ìš°ì„  ì¡°ì¹˜ì‚¬í•­:**\n")
                for action in rec['priority_actions']:
                    report.append(f"- {action}\n")
            
            if rec['improvements']:
                report.append("\n**ê°œì„ ì‚¬í•­:**\n")
                for improvement in rec['improvements']:
                    report.append(f"- {improvement}\n")
        
        return ''.join(report)
    
    def export_comparison(self, format: str = 'json') -> str:
        """ë¹„êµ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
        if format == 'json':
            return json.dumps(self.comparison_results, indent=2, default=str)
        elif format == 'markdown':
            return self.generate_comparison_report()
        else:
            raise ValueError(f"Unsupported format: {format}")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    comparator = ProjectComparator()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    project1_results = {
        'security': {
            'security_score': 85,
            'code_vulnerabilities': [
                {'severity': 'HIGH'},
                {'severity': 'MEDIUM'}
            ]
        },
        'dependencies': {
            'summary': {'external_packages': 15}
        }
    }
    
    project2_results = {
        'security': {
            'security_score': 65,
            'code_vulnerabilities': [
                {'severity': 'CRITICAL'},
                {'severity': 'HIGH'},
                {'severity': 'HIGH'},
                {'severity': 'MEDIUM'}
            ]
        },
        'dependencies': {
            'summary': {'external_packages': 25}
        }
    }
    
    # í”„ë¡œì íŠ¸ ì¶”ê°€
    id1 = comparator.add_project("Safe Project", project1_results)
    id2 = comparator.add_project("Risky Project", project2_results)
    
    # ë¹„êµ
    comparison = comparator.compare_projects()
    
    # ë³´ê³ ì„œ ìƒì„±
    report = comparator.generate_comparison_report()
    print(report)