# core/improved_llm_analyzer.py
"""
ê°œì„ ëœ LLM ë³´ì•ˆ ë¶„ì„ê¸°
- LLMì´ ììœ ë¡­ê²Œ ì·¨ì•½ì  ë°œê²¬
- RAGë¡œ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ì œì‹œ
"""
import os
import json
import re
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
from anthropic import Anthropic

class ImprovedSecurityAnalyzer:
    """AI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ê¸° - Claude ìš°ì„ """
    
    def __init__(self, use_claude: bool = True):
        """
        Args:
            use_claude: Claudeë¥¼ ìš°ì„  ì‚¬ìš©í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        self.use_claude = use_claude
        self.claude_client = None
        self.openai_client = None
        
        # Claude ì´ˆê¸°í™” (ìš°ì„ ìˆœìœ„ 1)
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                self.claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
                print("âœ… Claude API ì´ˆê¸°í™” ì„±ê³µ (ë©”ì¸ ì—”ì§„)")
            except Exception as e:
                print(f"âš ï¸ Claude ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # OpenAI ì´ˆê¸°í™” (ìš°ì„ ìˆœìœ„ 2 - í´ë°±)
        if os.getenv("OPENAI_API_KEY"):
            try:
                self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                print("âœ… OpenAI API ì´ˆê¸°í™” ì„±ê³µ (í´ë°± ì—”ì§„)")
            except Exception as e:
                print(f"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # API ê°€ìš©ì„± í™•ì¸
        if not self.claude_client and not self.openai_client:
            raise ValueError("âŒ Claudeì™€ OpenAI API ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì„ íƒì )
        self.rag = None
        try:
            from rag.simple_rag import SimpleRAG
            self.rag = SimpleRAG()
            print("âœ… RAG ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def analyze_security(self, code: str, file_list: List[Dict] = None) -> Dict:
        """ì½”ë“œ ë³´ì•ˆ ë¶„ì„ - ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ """
        
        print("ğŸ” AI ë³´ì•ˆ ë¶„ì„ ì‹œì‘...")
        
        # 1ë‹¨ê³„: AIê°€ ì·¨ì•½ì  ë°œê²¬ ë° ìˆ˜ì • ì½”ë“œ ìƒì„±
        vulnerabilities = self._discover_vulnerabilities(code, file_list)
        
        # ì˜¤ë¥˜ ì²´í¬
        has_error = False
        error_message = ""
        
        if vulnerabilities:
            # íŒŒì‹± ì˜¤ë¥˜ë‚˜ í† í° ì˜¤ë¥˜ ì²´í¬
            for vuln in vulnerabilities:
                if vuln.get('parse_error') or vuln.get('token_error'):
                    has_error = True
                    error_message = vuln.get('description', 'AI ë¶„ì„ ì˜¤ë¥˜')
                    break
        
        if has_error:
            return {
                'success': False,
                'vulnerabilities': vulnerabilities,
                'security_score': 0,
                'summary': f'âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {error_message}',
                'analyzed_by': 'Error',
                'has_error': True,
                'error_type': vulnerabilities[0].get('type', 'Unknown Error')
            }
        
        # ì •ìƒ ì²˜ë¦¬
        if not vulnerabilities:
            return {
                'success': True,
                'vulnerabilities': [],
                'security_score': 100,
                'summary': 'ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'analyzed_by': 'AI',
                'has_error': False
            }
        
        # 2ë‹¨ê³„: RAGë¡œ ê° ì·¨ì•½ì ì— ëŒ€í•œ ê·¼ê±° ì°¾ê¸°
        if self.rag:
            vulnerabilities = self._add_rag_evidence(vulnerabilities)
        
        # 3ë‹¨ê³„: ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°
        security_score = self._calculate_security_score(vulnerabilities)
        
        # 4ë‹¨ê³„: ìš”ì•½ ìƒì„±
        summary = self._generate_summary(vulnerabilities)
        
        return {
            'success': True,
            'vulnerabilities': vulnerabilities,
            'security_score': security_score,
            'summary': summary,
            'analyzed_by': 'Claude' if self.use_claude and self.claude_client else 'GPT',
            'has_error': False
        }
    


    def _discover_vulnerabilities(self, code: str, file_list: List[Dict] = None) -> List[Dict]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì·¨ì•½ì  ë°œê²¬ - use_claude íŒŒë¼ë¯¸í„° ì ìš©"""
        
        prompt = self._build_discovery_prompt(code, file_list)
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        vulnerabilities = []
        
        # use_claude ì„¤ì •ì— ë”°ë¼ ìˆœì„œ ê²°ì •
        if self.use_claude:
            # 1. Claude ìš°ì„  ëª¨ë“œ
            if self.claude_client:
                try:
                    print("ğŸ­ Claude ë¶„ì„ ì‹œì‘ (ìš°ì„  ì—”ì§„)...")
                    vulnerabilities = self._analyze_with_claude(prompt)
                    
                    if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                        print(f"âœ… Claude ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                        return vulnerabilities
                    elif vulnerabilities:
                        print("âš ï¸ Claude íŒŒì‹± ì˜¤ë¥˜, GPTë¡œ í´ë°±")
                except Exception as e:
                    print(f"âš ï¸ Claude ë¶„ì„ ì‹¤íŒ¨: {e}, GPTë¡œ í´ë°±")
            else:
                print("âš ï¸ Claude API ì—†ìŒ, GPTë¡œ ì „í™˜")
            
            # Claude ì‹¤íŒ¨ ì‹œ GPT í´ë°±
            if self.openai_client and not (vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities)):
                try:
                    print("ğŸ¤– GPT ë¶„ì„ ì‹œì‘ (í´ë°±)...")
                    vulnerabilities = self._analyze_with_gpt(prompt)
                    
                    if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                        print(f"âœ… GPT ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                        return vulnerabilities
                except Exception as e:
                    print(f"âŒ GPT ë¶„ì„ë„ ì‹¤íŒ¨: {e}")
        
        else:
            # 2. GPT ì „ìš© ëª¨ë“œ (use_claude=False)
            if self.openai_client:
                try:
                    print("ğŸ¤– GPT ë¶„ì„ ì‹œì‘ (ì „ìš© ëª¨ë“œ)...")
                    vulnerabilities = self._analyze_with_gpt(prompt)
                    
                    if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                        print(f"âœ… GPT ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                        return vulnerabilities
                except Exception as e:
                    print(f"âŒ GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
                    # GPT ì‹¤íŒ¨ ì‹œ Claude ì‹œë„ (ìˆë‹¤ë©´)
                    if self.claude_client:
                        try:
                            print("ğŸ­ Claudeë¡œ ì¬ì‹œë„...")
                            vulnerabilities = self._analyze_with_claude(prompt)
                            
                            if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                                print(f"âœ… Claude ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                                return vulnerabilities
                        except Exception as e2:
                            print(f"âŒ Claudeë„ ì‹¤íŒ¨: {e2}")
            else:
                print("âŒ OpenAI API ì—†ìŒ")
        
        # 3. ëª¨ë‘ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜
        if not vulnerabilities:
            vulnerabilities = [{
                "type": "Analysis Failed",
                "severity": "ERROR",
                "confidence": "HIGH",
                "location": {"file": "unknown", "line": 0, "function": "unknown"},
                "description": "AI ë¶„ì„ ì‹¤íŒ¨: ëª¨ë“  AI ì—”ì§„ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                "vulnerable_code": "ë¶„ì„ ë¶ˆê°€",
                "fixed_code": "ë¶„ì„ ë¶ˆê°€",
                "fix_explanation": "API í‚¤ì™€ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "recommendation": "1. .env íŒŒì¼ í™•ì¸\n2. API í¬ë ˆë”§ í™•ì¸\n3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸",
                "parse_error": True
            }]
        
        return vulnerabilities
    
    
    def _build_discovery_prompt(self, code: str, file_list: List[Dict] = None) -> str:
        """ì·¨ì•½ì  ë°œê²¬ í”„ë¡¬í”„íŠ¸ - JSON ì‘ë‹µ ê°•ì œ"""
        
        file_info = ""
        if file_list:
            file_info = f"\në¶„ì„ ëŒ€ìƒ: {len(file_list)}ê°œ íŒŒì¼\n"
            for f in file_list[:5]:
                file_info += f"- {f['path']} ({f['lines']}ì¤„)\n"
        
        # ì½”ë“œ ê¸¸ì´ ì œí•œ
        max_code_length = 25000  # í”„ë¡¬í”„íŠ¸ ê³µê°„ í™•ë³´
        if len(code) > max_code_length:
            code = code[:max_code_length] + "\n# ... (ì½”ë“œê°€ ì˜ë ¸ìŠµë‹ˆë‹¤)"
        
        prompt = f"""Python ë³´ì•ˆ ì „ë¬¸ê°€ë¡œì„œ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

    {file_info}

    ë¶„ì„í•  ì½”ë“œ:
    {code}

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì¸ì‚¬ë§ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:

    {{
        "vulnerabilities": [
            {{
                "type": "ì·¨ì•½ì íƒ€ì…",
                "severity": "CRITICAL/HIGH/MEDIUM/LOW",
                "confidence": "HIGH/MEDIUM/LOW",
                "location": {{
                    "file": "íŒŒì¼ëª…",
                    "line": ìˆ«ì,
                    "function": "í•¨ìˆ˜ëª…",
                    "code_snippet": "ë¬¸ì œì½”ë“œ"
                }},
                "description": "í•œêµ­ì–´ì„¤ëª…",
                "vulnerable_code": "ì·¨ì•½í•œì½”ë“œ",
                "fixed_code": "ìˆ˜ì •ëœì½”ë“œ",
                "fix_explanation": "ìˆ˜ì •ì„¤ëª…",
                "data_flow": "ë°ì´í„°íë¦„",
                "exploit_scenario": "ê³µê²©ì‹œë‚˜ë¦¬ì˜¤",
                "recommendation": "ê¶Œì¥ì‚¬í•­"
            }}
        ]
    }}

    ì£¼ì˜: JSONë§Œ ì¶œë ¥. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ìŒ."""
    
        return prompt
    
    def _analyze_with_claude(self, prompt: str) -> List[Dict]:
        """Claudeë¡œ ë¶„ì„ - Claude íŠ¹í™” í”„ë¡¬í”„íŠ¸"""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
            model = os.getenv("ANTHROPIC_MODEL")
            if not model:
                model = "claude-3-opus-20240229"
                print(f"âš ï¸ ANTHROPIC_MODEL ë¯¸ì„¤ì •, ê¸°ë³¸ê°’ ì‚¬ìš©: {model}")
            
            # ClaudeëŠ” system roleì´ ì—†ìœ¼ë¯€ë¡œ user ë©”ì‹œì§€ì— í†µí•©
            claude_prompt = """You are a senior security expert analyzing Python code.
    Respond ONLY with valid JSON. No explanations, no markdown.

    """ + prompt
            
            response = self.claude_client.messages.create(
                model=model,
                max_tokens=4000,
                temperature=0.2,
                messages=[
                    {
                        "role": "user",
                        "content": claude_prompt
                    }
                ]
            )
            
            # Claude ì‘ë‹µ ì¶”ì¶œ (content[0].text)
            result_text = response.content[0].text
            
            # ì‘ë‹µ ë¡œê¹…
            print(f"ğŸ“ Claude ì‘ë‹µ ê¸¸ì´: {len(result_text)}")
            if len(result_text) < 50:
                print(f"âš ï¸ ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ: {result_text}")
            
            vulnerabilities = self._parse_json_response(result_text)
            return vulnerabilities
            
        except AttributeError as e:
            # Claude ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ ì²˜ë¦¬
            print(f"âŒ Claude ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {e}")
            if 'response' in locals():
                print(f"ì‘ë‹µ êµ¬ì¡°: {type(response)}")
            raise
        except json.JSONDecodeError as e:
            print(f"âŒ Claude JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_parse_error(str(e), result_text[:500] if 'result_text' in locals() else "")
        except Exception as e:
            print(f"âŒ Claude í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    def _analyze_with_gpt(self, prompt: str) -> List[Dict]:
        """GPTë¡œ ë¶„ì„ - GPT íŠ¹í™” ì„¤ì •"""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
            model = os.getenv("OPENAI_MODEL")
            if not model:
                model = "gpt-4-turbo-preview"
                print(f"âš ï¸ OPENAI_MODEL ë¯¸ì„¤ì •, ê¸°ë³¸ê°’ ì‚¬ìš©: {model}")
            
            # í† í° ê¸¸ì´ ì²´í¬
            prompt_length = len(prompt)
            estimated_tokens = prompt_length // 4
            
            if estimated_tokens > 8000:
                print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ê¹ë‹ˆë‹¤ ({estimated_tokens} í† í° ì˜ˆìƒ)")
            
            # GPTëŠ” response_format ì§€ì› í™•ì¸
            kwargs = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a JSON API that analyzes Python code for vulnerabilities. Respond only with valid JSON. No markdown, no explanations."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.2,
                "max_tokens": 3000
            }
            
            # GPT-4 ëª¨ë¸ë§Œ response_format ì§€ì›
            if "gpt-4" in model:
                kwargs["response_format"] = {"type": "json_object"}
            
            response = self.openai_client.chat.completions.create(**kwargs)
            
            # GPT ì‘ë‹µ ì¶”ì¶œ (choices[0].message.content)
            result_text = response.choices[0].message.content
            
            print(f"ğŸ“ GPT ì‘ë‹µ ê¸¸ì´: {len(result_text)}")
            
            vulnerabilities = self._parse_json_response(result_text)
            return vulnerabilities
            
        except AttributeError as e:
            # GPT ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ ì²˜ë¦¬
            print(f"âŒ GPT ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {e}")
            if 'response' in locals():
                print(f"ì‘ë‹µ êµ¬ì¡°: {type(response)}")
            raise
        except json.JSONDecodeError as e:
            print(f"âŒ GPT JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_parse_error(str(e), result_text[:500] if 'result_text' in locals() else "")
        except Exception as e:
            print(f"âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    def _create_parse_error(self, error_msg: str, response_snippet: str) -> List[Dict]:
        """íŒŒì‹± ì—ëŸ¬ ê°ì²´ ìƒì„±"""
        return [{
            "type": "Parse Error",
            "severity": "ERROR",
            "confidence": "HIGH",
            "location": {"file": "unknown", "line": 0, "function": "parse_error"},
            "description": f"JSON íŒŒì‹± ì‹¤íŒ¨: {error_msg}",
            "vulnerable_code": f"ì‘ë‹µ ì¼ë¶€:\n{response_snippet}",
            "fixed_code": "ì¬ì‹œë„ í•„ìš”",
            "fix_explanation": "AIê°€ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "recommendation": "1. ì½”ë“œë¥¼ ì¤„ì—¬ë³´ì„¸ìš”\n2. ë‹¤ë¥¸ AI ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”\n3. ë‹¤ì‹œ ë¶„ì„ì„ ì‹œë„í•´ë³´ì„¸ìš”",
            "parse_error": True
        }]

    def _parse_json_response(self, response_text: str) -> List[Dict]:
        """ê°•í™”ëœ JSON íŒŒì‹± í•¨ìˆ˜ - ë””ë²„ê¹… í¬í•¨"""
        
        original_text = response_text  # ì›ë³¸ ë³´ì¡´
        
        print(f"ğŸ” ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response_text)} ë¬¸ì")
        print(f"ğŸ” ì‘ë‹µ ì‹œì‘ ë¶€ë¶„: {response_text[:200]}...")
        
        # 1. JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        json_text = None
        
        # ë°©ë²• 1: ```json ë¸”ë¡
        if "```json" in response_text:
            start = response_text.find("```json") + 7
            end = response_text.find("```", start)
            if end > start:
                json_text = response_text[start:end].strip()
                print("âœ… ```json ë¸”ë¡ ë°œê²¬")
        
        # ë°©ë²• 2: ``` ë¸”ë¡
        elif "```" in response_text:
            start = response_text.find("```") + 3
            end = response_text.find("```", start)
            if end > start:
                json_text = response_text[start:end].strip()
                print("âœ… ``` ë¸”ë¡ ë°œê²¬")
        
        # ë°©ë²• 3: ì¤‘ê´„í˜¸ ì°¾ê¸°
        if not json_text and "{" in response_text:
            # ì²« ë²ˆì§¸ { ì°¾ê¸°
            start = response_text.find("{")
            if start >= 0:
                # ë§¤ì¹­ë˜ëŠ” } ì°¾ê¸° (ê°„ë‹¨í•œ ë°©ë²•)
                brace_count = 0
                end = start
                for i in range(start, len(response_text)):
                    if response_text[i] == "{":
                        brace_count += 1
                    elif response_text[i] == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            end = i + 1
                            break
                
                if end > start:
                    json_text = response_text[start:end]
                    print(f"âœ… ì¤‘ê´„í˜¸ ê¸°ë°˜ ì¶”ì¶œ: {start}:{end}")
        
        # JSONì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‹œë„
        if not json_text:
            json_text = response_text.strip()
            print("âš ï¸ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì „ì²´ í…ìŠ¤íŠ¸ ì‹œë„")
        
        # 2. íŒŒì‹± ì „ ì •ë¦¬
        json_text = self._clean_json_text(json_text)
        
        print(f"ğŸ” ì •ë¦¬ëœ JSON ì‹œì‘: {json_text[:100]}...")
        
        # 3. íŒŒì‹± ì‹œë„
        try:
            result = json.loads(json_text)
            vulnerabilities = result.get('vulnerabilities', [])
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
            return vulnerabilities
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"âŒ ë¬¸ì œ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
            
            # ë¬¸ì œ ë¶€ë¶„ ì¶œë ¥
            lines = json_text.split('\n')
            if e.lineno <= len(lines):
                print(f"âŒ ë¬¸ì œ ë¼ì¸: {lines[e.lineno-1]}")
            
            # ë§ˆì§€ë§‰ ì‹œë„: ë” ê³µê²©ì ì¸ ì •ë¦¬
            try:
                json_text = self._aggressive_clean(original_text)
                result = json.loads(json_text)
                print("âœ… ê³µê²©ì  ì •ë¦¬ í›„ íŒŒì‹± ì„±ê³µ")
                return result.get('vulnerabilities', [])
            except:
                # ì™„ì „ ì‹¤íŒ¨
                raise e

    def _clean_json_text(self, text: str) -> str:
        """JSON í…ìŠ¤íŠ¸ ì •ë¦¬"""
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        # BOM ì œê±°
        if text.startswith('\ufeff'):
            text = text[1:]
        
        # ì¼ë°˜ì ì¸ ì ‘ë‘ì‚¬ ì œê±°
        prefixes = [
            "Here is the JSON response:",
            "Here's the analysis:",
            "JSON:",
            "```json",
            "```"
        ]
        
        for prefix in prefixes:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
        
        # ì¼ë°˜ì ì¸ ì ‘ë¯¸ì‚¬ ì œê±°
        suffixes = [
            "```",
            "I hope this helps!",
            "Let me know if you need",
        ]
        
        for suffix in suffixes:
            if text.endswith(suffix):
                text = text[:-len(suffix)].strip()
        
        return text

    def _aggressive_clean(self, text: str) -> str:
        """ê³µê²©ì ì¸ JSON ì¶”ì¶œ (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        import re
        
        # ëª¨ë“  ê°€ëŠ¥í•œ JSON íŒ¨í„´ ì°¾ê¸°
        patterns = [
            r'\{[\s\S]*"vulnerabilities"[\s\S]*\}',  # vulnerabilitiesë¥¼ í¬í•¨í•˜ëŠ” JSON
            r'\{[^{}]*\{[^{}]*\}[^{}]*\}',  # ì¤‘ì²©ëœ ê°ì²´
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            if matches:
                # ê°€ì¥ ê¸´ ë§¤ì¹˜ ì„ íƒ
                longest = max(matches, key=len)
                try:
                    # í…ŒìŠ¤íŠ¸ íŒŒì‹±
                    json.loads(longest)
                    print(f"âœ… ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ JSON ì¶”ì¶œ ì„±ê³µ")
                    return longest
                except:
                    continue
        
        # ì‹¤íŒ¨
        return text

    def _fix_common_json_errors(self, text: str) -> str:
        """ì¼ë°˜ì ì¸ JSON ì˜¤ë¥˜ ìˆ˜ì •"""
        
        # ì¤„ë°”ê¿ˆ ì²˜ë¦¬
        text = text.replace('\n', '\\n')
        text = text.replace('\r', '\\r')
        text = text.replace('\t', '\\t')
        
        # ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
        # ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ëœ ê²ƒì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        text = text.replace('\\\\', '__DOUBLE_BACKSLASH__')
        text = text.replace('\\"', '__ESCAPED_QUOTE__')
        
        # JSON ë‚´ë¶€ì˜ ë”°ì˜´í‘œ ì²˜ë¦¬ (ë§¤ìš° ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ)
        # ... ë³µì¡í•œ ë¡œì§ í•„ìš”
        
        # ì„ì‹œ ì¹˜í™˜ ë³µì›
        text = text.replace('__ESCAPED_QUOTE__', '\\"')
        text = text.replace('__DOUBLE_BACKSLASH__', '\\\\')
        
        # ë§ë¯¸ ì‰¼í‘œ ì œê±°
        text = re.sub(r',\s*}', '}', text)
        text = re.sub(r',\s*]', ']', text)
        
        return text

    def _aggressive_json_fix(self, text: str) -> str:
        """ë” ê³µê²©ì ì¸ JSON ìˆ˜ì • (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        import re
        
        # ëª¨ë“  ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        text = ' '.join(text.split())
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ë¬¸ìì—´ ë‚´ë¶€ì˜ ë”°ì˜´í‘œ ì²˜ë¦¬
        # "key": "value with "quotes" inside" -> "key": "value with \"quotes\" inside"
        # ì´ê²ƒì€ ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ ê²½ìš°ë§Œ ì²˜ë¦¬
        
        return text
        
    
    # core/improved_llm_analyzer.py


    def _add_rag_evidence(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """ê° ì·¨ì•½ì ì— RAG ê·¼ê±° ì¶”ê°€ - ê°œì„ ëœ ë²„ì „"""
        if not self.rag:
            return vulnerabilities
        
        print("ğŸ“š RAGë¡œ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ì°¾ëŠ” ì¤‘...")
        try:
            for vuln in vulnerabilities:
                vuln_type = vuln.get('type', '')
                
                # RAGì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
                search_query = f"{vuln_type} ë°©ì–´ ë°©ë²• ë³´ì•ˆ ê°€ì´ë“œë¼ì¸"
                results = self.rag.search_similar(search_query, top_k=3)  # top_kë¥¼ 3ìœ¼ë¡œ ì¦ê°€
                
                if results['documents'] and results['documents'][0]:
                    # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ
                    evidence = results['documents'][0][0]
                    
                    # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìƒì„¸ ì •ë³´ ì¶”ê°€
                    if results.get('metadatas') and results['metadatas'][0]:
                        metadata = results['metadatas'][0][0]
                        
                        # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
                        page = metadata.get('page', '?')
                        page_start = metadata.get('page_start', page)
                        page_end = metadata.get('page_end', page)
                        
                        # í˜ì´ì§€ ë²”ìœ„ ê²°ì •
                        if page_start and page_end and page_start != page_end:
                            page_info = f"{page_start}-{page_end}"
                        else:
                            page_info = str(page)
                        
                        vuln['evidence'] = {
                            'source': 'KISIA Python ì‹œíì–´ì½”ë”© ê°€ì´ë“œ',
                            'document': 'Python_ì‹œíì–´ì½”ë”©_ê°€ì´ë“œ(2023ë…„_ê°œì •ë³¸).pdf',
                            'page': page_info,
                            'page_start': page_start,
                            'page_end': page_end,
                            'section_title': metadata.get('title', ''),
                            'vulnerability_types': metadata.get('vulnerability_types', ''),
                            'content': evidence[:500] + "..." if len(evidence) > 500 else evidence,
                            'full_content': evidence,  # ì „ì²´ ë‚´ìš© ë³´ê´€
                            'collection': results.get('collection_name', 'unknown')
                        }
                        
                        # ì¶”ê°€ ê´€ë ¨ ë¬¸ì„œë“¤ë„ ì €ì¥ (ìˆìœ¼ë©´)
                        if len(results['documents'][0]) > 1:
                            related_docs = []
                            for i in range(1, min(3, len(results['documents'][0]))):
                                if i < len(results['metadatas'][0]):
                                    related_meta = results['metadatas'][0][i]
                                    related_docs.append({
                                        'page': related_meta.get('page', '?'),
                                        'type': related_meta.get('type', ''),
                                        'keywords': related_meta.get('keywords', '')
                                    })
                            vuln['evidence']['related_sections'] = related_docs
                    else:
                        vuln['evidence'] = {
                            'source': 'KISIA ê°€ì´ë“œë¼ì¸',
                            'content': evidence[:500] + "..." if len(evidence) > 500 else evidence
                        }
            
            return vulnerabilities
        except Exception as e:
            print(f"âš ï¸ RAG ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return vulnerabilities
        
    def _calculate_security_score(self, vulnerabilities: List[Dict]) -> int:
        """ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°"""
        if not vulnerabilities:
            return 100
        
        score = 100
        
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'MEDIUM')
            confidence = vuln.get('confidence', 'MEDIUM')
            
            # ì‹¬ê°ë„ë³„ ê°ì  (ì™„í™”ëœ ê¸°ì¤€)
            severity_penalty = {
                'CRITICAL': 24,
                'HIGH': 14,
                'MEDIUM': 6,
                'LOW': 2
            }.get(severity, 6)
            
            # í™•ì‹ ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            confidence_weight = {
                'HIGH': 1.0,
                'MEDIUM': 0.7,
                'LOW': 0.4
            }.get(confidence, 0.7)
            
            score -= int(severity_penalty * confidence_weight)
        
        return max(0, score)
    
    def _generate_summary(self, vulnerabilities: List[Dict]) -> str:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""
        if not vulnerabilities:
            return "ì½”ë“œ ë¶„ì„ ê²°ê³¼ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        total = len(vulnerabilities)
        critical = sum(1 for v in vulnerabilities if v.get('severity') == 'CRITICAL')
        high = sum(1 for v in vulnerabilities if v.get('severity') == 'HIGH')
        
        summary = f"ì´ {total}ê°œì˜ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        
        if critical > 0:
            summary += f" (CRITICAL: {critical}ê°œ)"
        if high > 0:
            summary += f" (HIGH: {high}ê°œ)"
        
        # ì£¼ìš” ì·¨ì•½ì  íƒ€ì…
        vuln_types = list(set(v.get('type', 'Unknown') for v in vulnerabilities))
        if vuln_types:
            summary += f". ì£¼ìš” ìœ í˜•: {', '.join(vuln_types[:3])}"
        
        return summary


# ê°„ë‹¨í•œ ì‚¬ìš© í—¬í¼ í•¨ìˆ˜
def analyze_code_with_ai(code: str, file_list: List[Dict] = None, use_claude: bool = True) -> Dict:
    """
    ì½”ë“œë¥¼ AIë¡œ ë¶„ì„í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        code: ë¶„ì„í•  Python ì½”ë“œ
        file_list: íŒŒì¼ ëª©ë¡
        use_claude: Claude ìš°ì„  ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    analyzer = ImprovedSecurityAnalyzer(use_claude=use_claude)
    return analyzer.analyze_security(code, file_list)