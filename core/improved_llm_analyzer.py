# core/improved_llm_analyzer.py
"""
ê°œì„ ëœ LLM ë³´ì•ˆ ë¶„ì„ê¸°
- LLMì´ ììœ ë¡­ê²Œ ì·¨ì•½ì  ë°œê²¬
- RAGë¡œ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ì œì‹œ
"""
import os
import json
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
from anthropic import Anthropic

class ImprovedSecurityAnalyzer:
    """AI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ê¸° - íŒ¨í„´ ë§¤ì¹­ ì—†ì´ ììœ ë¡œìš´ ë¶„ì„"""
    
    def __init__(self, use_claude: bool = True):
        """
        Args:
            use_claude: Claudeë¥¼ ìš°ì„  ì‚¬ìš©í• ì§€ ì—¬ë¶€
        """
        self.use_claude = use_claude
        self.claude_client = None
        self.openai_client = None
        
        # Claude ì´ˆê¸°í™”
        if use_claude and os.getenv("ANTHROPIC_API_KEY"):
            try:
                self.claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
                print("âœ… Claude API ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸ Claude ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # OpenAI ì´ˆê¸°í™”
        if os.getenv("OPENAI_API_KEY"):
            try:
                self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                print("âœ… OpenAI API ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì„ íƒì )
        self.rag = None
        try:
            from rag.simple_rag import SimpleRAG
            self.rag = SimpleRAG()
            print("âœ… RAG ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def analyze_security(self, code: str, file_list: List[Dict] = None) -> Dict:
        """
        ì½”ë“œ ë³´ì•ˆ ë¶„ì„ - ììœ ë¡œìš´ AI ë¶„ì„
        
        Args:
            code: ë¶„ì„í•  Python ì½”ë“œ
            file_list: íŒŒì¼ ëª©ë¡ ì •ë³´
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("ğŸ” AI ë³´ì•ˆ ë¶„ì„ ì‹œì‘...")
        
        # 1ë‹¨ê³„: AIê°€ ììœ ë¡­ê²Œ ì·¨ì•½ì  ë°œê²¬
        vulnerabilities = self._discover_vulnerabilities(code, file_list)
        
        if not vulnerabilities:
            return {
                'success': True,
                'vulnerabilities': [],
                'security_score': 100,
                'summary': 'ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'analyzed_by': 'AI'
            }
        
        # 2ë‹¨ê³„: RAGë¡œ ê° ì·¨ì•½ì ì— ëŒ€í•œ ê·¼ê±° ì°¾ê¸°
        if self.rag:
            vulnerabilities = self._add_rag_evidence(vulnerabilities)
        
        # 3ë‹¨ê³„: ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°
        security_score = self._calculate_security_score(vulnerabilities)
        
        # 4ë‹¨ê³„: ìš”ì•½ ìƒì„±
        summary = self._generate_summary(vulnerabilities)
        
        return {
            'success': True,
            'vulnerabilities': vulnerabilities,
            'security_score': security_score,
            'summary': summary,
            'analyzed_by': 'Claude' if self.use_claude and self.claude_client else 'GPT'
        }
    
    def _discover_vulnerabilities(self, code: str, file_list: List[Dict] = None) -> List[Dict]:
        """AIê°€ ììœ ë¡­ê²Œ ì·¨ì•½ì  ë°œê²¬"""
        
        # í”„ë¡¬í”„íŠ¸ - íŒ¨í„´ ë§¤ì¹­ì´ ì•„ë‹Œ ì¶”ë¡  ìœ ë„
        prompt = self._build_discovery_prompt(code, file_list)
        
        # Claude ìš°ì„  ì‹œë„
        if self.use_claude and self.claude_client:
            try:
                return self._analyze_with_claude(prompt)
            except Exception as e:
                print(f"âš ï¸ Claude ë¶„ì„ ì‹¤íŒ¨, GPTë¡œ ì „í™˜: {e}")
        
        # GPTë¡œ ë¶„ì„
        if self.openai_client:
            try:
                return self._analyze_with_gpt(prompt)
            except Exception as e:
                print(f"âŒ GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return []
    
    def _build_discovery_prompt(self, code: str, file_list: List[Dict] = None) -> str:
        """ì·¨ì•½ì  ë°œê²¬ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # íŒŒì¼ ì •ë³´ ì¶”ê°€
        file_info = ""
        if file_list:
            file_info = f"\në¶„ì„ ëŒ€ìƒ: {len(file_list)}ê°œ íŒŒì¼\n"
            for f in file_list[:5]:  # ìƒìœ„ 5ê°œë§Œ
                file_info += f"- {f['path']} ({f['lines']}ì¤„)\n"
        
        prompt = f"""
ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ Python ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë³´ì•ˆ ì·¨ì•½ì ì„ ì°¾ì•„ì£¼ì„¸ìš”.

{file_info}

**ì¤‘ìš”í•œ ë¶„ì„ ì§€ì¹¨:**
1. ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ì„ ì°¾ì§€ ë§ê³ , ì½”ë“œì˜ ì‹¤ì œ ë™ì‘ì„ ì´í•´í•˜ì„¸ìš”
2. ë°ì´í„° íë¦„ì„ ì¶”ì í•˜ì„¸ìš”: ì™¸ë¶€ ì…ë ¥ â†’ ì²˜ë¦¬ â†’ ì¶œë ¥/ì €ì¥
3. ê° í•¨ìˆ˜ê°€ ë¬´ì—‡ì„ í•˜ëŠ”ì§€, ì–´ë–¤ ìœ„í—˜ì´ ìˆëŠ”ì§€ ì¶”ë¡ í•˜ì„¸ìš”
4. ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì„¸ìš”: ê°™ì€ ì½”ë“œë¼ë„ ìƒí™©ì— ë”°ë¼ ìœ„í—˜ë„ê°€ ë‹¤ë¦…ë‹ˆë‹¤

**ë¶„ì„ ë°©ë²•:**
Step 1: ì™¸ë¶€ ì…ë ¥ì  ì‹ë³„ (user input, file, network, env)
Step 2: ê° ì…ë ¥ì´ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ëŠ”ì§€ ì¶”ì 
Step 3: ìœ„í—˜í•œ ì‘ì—…ìœ¼ë¡œ íë¥´ëŠ”ì§€ í™•ì¸ (DB, file, system, network)
Step 4: ê²€ì¦/ì´ìŠ¤ì¼€ì´í”„ ê³¼ì •ì´ ìˆëŠ”ì§€ í™•ì¸
Step 5: ì‹¤ì œ ì•…ìš© ê°€ëŠ¥í•œì§€ íŒë‹¨

**ì½”ë“œ:**
```python
{code[:30000]}  # í† í° ì œí•œ
```

ë°œê²¬í•œ ëª¨ë“  ì·¨ì•½ì ì„ JSON í˜•ì‹ìœ¼ë¡œ ë³´ê³ í•˜ì„¸ìš”:
{{
    "vulnerabilities": [
        {{
            "type": "ì·¨ì•½ì  ìœ í˜• (ì˜ˆ: SQL Injection, XSS ë“±)",
            "severity": "CRITICAL/HIGH/MEDIUM/LOW",
            "confidence": "HIGH/MEDIUM/LOW (í™•ì‹ ë„)",
            "location": {{
                "file": "íŒŒì¼ëª…",
                "line": ë¼ì¸ë²ˆí˜¸,
                "function": "í•¨ìˆ˜ëª…"
            }},
            "description": "ì·¨ì•½ì  ì„¤ëª…",
            "data_flow": "ë°ì´í„°ê°€ ì–´ë–»ê²Œ í˜ëŸ¬ì„œ ìœ„í—˜í•´ì§€ëŠ”ì§€",
            "exploit_scenario": "ì‹¤ì œ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤",
            "recommendation": "ê°œì„  ë°©ë²•"
        }}
    ]
}}

ì¶”ë¡  ê³¼ì •ì„ ë³´ì—¬ì£¼ë˜, ìµœì¢… ì‘ë‹µì€ ë°˜ë“œì‹œ JSONë§Œ í¬í•¨í•˜ì„¸ìš”.
- JSON í‚¤(key)ëŠ” ì˜ì–´ ìœ ì§€
- JSON ê°’(value) ì¤‘ ì„¤ëª…, ì´ìœ , ì‹œë‚˜ë¦¬ì˜¤, ê¶Œì¥ì‚¬í•­ ë“± ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
"""
        return prompt
    
    # core/improved_llm_analyzer.py
    # _analyze_with_claude() í•¨ìˆ˜ ìˆ˜ì • (ë¼ì¸ 246 ê·¼ì²˜)

    def _analyze_with_claude(self, prompt: str) -> List[Dict]:
        """Claudeë¡œ ë¶„ì„"""
        response = self.claude_client.messages.create(
            model="claude-opus-4-20250514",  # ì˜¤íƒ€ ìˆ˜ì •: 202402299 â†’ 20240229
            max_tokens=4000,
            temperature=0.3,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ
        
        # JSON íŒŒì‹±
        result_text = response.content[0].text
        
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        elif "{" in result_text:
            # JSON ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
            start = result_text.find("{")
            end = result_text.rfind("}") + 1
            if start >= 0 and end > start:
                result_text = result_text[start:end]
        
        try:
            result = json.loads(result_text.strip())
            return result.get('vulnerabilities', [])
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
    
    def _analyze_with_gpt(self, prompt: str) -> List[Dict]:
        """GPTë¡œ ë¶„ì„"""
        response = self.openai_client.chat.completions.create(
            model="gpt-4" if "gpt-4" in os.getenv("OPENAI_MODEL", "") else "gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "You are a security expert. Analyze code for vulnerabilities. Respond with JSON only."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
            max_tokens=2000
        )
        
        result_text = response.choices[0].message.content
        
        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        
        try:
            result = json.loads(result_text.strip())
            return result.get('vulnerabilities', [])
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
    
    def _add_rag_evidence(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """ê° ì·¨ì•½ì ì— RAG ê·¼ê±° ì¶”ê°€"""
        if not self.rag:
            return vulnerabilities
        
        print("ğŸ“š RAGë¡œ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ì°¾ëŠ” ì¤‘...")
        
        for vuln in vulnerabilities:
            vuln_type = vuln.get('type', '')
            
            # RAGì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
            search_query = f"{vuln_type} ë°©ì–´ ë°©ë²• ë³´ì•ˆ ê°€ì´ë“œë¼ì¸"
            results = self.rag.search_similar(search_query, top_k=2)
            
            if results['documents'] and results['documents'][0]:
                # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ
                evidence = results['documents'][0][0]
                
                # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ í˜ì´ì§€ ì •ë³´ ì¶”ê°€
                if results.get('metadatas') and results['metadatas'][0]:
                    page = results['metadatas'][0][0].get('page', '?')
                    vuln['evidence'] = {
                        'source': 'KISIA Python ì‹œíì–´ì½”ë”© ê°€ì´ë“œ',
                        'page': page,
                        'content': evidence[:500] + "..." if len(evidence) > 500 else evidence
                    }
                else:
                    vuln['evidence'] = {
                        'source': 'KISIA ê°€ì´ë“œë¼ì¸',
                        'content': evidence[:500] + "..." if len(evidence) > 500 else evidence
                    }
        
        return vulnerabilities
    
    def _calculate_security_score(self, vulnerabilities: List[Dict]) -> int:
        """ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°"""
        if not vulnerabilities:
            return 100
        
        score = 100
        
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'MEDIUM')
            confidence = vuln.get('confidence', 'MEDIUM')
            
            # ì‹¬ê°ë„ë³„ ê°ì 
            severity_penalty = {
                'CRITICAL': 25,
                'HIGH': 15,
                'MEDIUM': 10,
                'LOW': 5
            }.get(severity, 10)
            
            # í™•ì‹ ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            confidence_weight = {
                'HIGH': 1.0,
                'MEDIUM': 0.7,
                'LOW': 0.4
            }.get(confidence, 0.7)
            
            score -= int(severity_penalty * confidence_weight)
        
        return max(0, score)
    
    def _generate_summary(self, vulnerabilities: List[Dict]) -> str:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""
        if not vulnerabilities:
            return "ì½”ë“œ ë¶„ì„ ê²°ê³¼ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        total = len(vulnerabilities)
        critical = sum(1 for v in vulnerabilities if v.get('severity') == 'CRITICAL')
        high = sum(1 for v in vulnerabilities if v.get('severity') == 'HIGH')
        
        summary = f"ì´ {total}ê°œì˜ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        
        if critical > 0:
            summary += f" (CRITICAL: {critical}ê°œ)"
        if high > 0:
            summary += f" (HIGH: {high}ê°œ)"
        
        # ì£¼ìš” ì·¨ì•½ì  íƒ€ì…
        vuln_types = list(set(v.get('type', 'Unknown') for v in vulnerabilities))
        if vuln_types:
            summary += f". ì£¼ìš” ìœ í˜•: {', '.join(vuln_types[:3])}"
        
        return summary


# ê°„ë‹¨í•œ ì‚¬ìš© í—¬í¼ í•¨ìˆ˜
def analyze_code_with_ai(code: str, file_list: List[Dict] = None, use_claude: bool = True) -> Dict:
    """
    ì½”ë“œë¥¼ AIë¡œ ë¶„ì„í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        code: ë¶„ì„í•  Python ì½”ë“œ
        file_list: íŒŒì¼ ëª©ë¡
        use_claude: Claude ìš°ì„  ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    analyzer = ImprovedSecurityAnalyzer(use_claude=use_claude)
    return analyzer.analyze_security(code, file_list)