# core/improved_llm_analyzer.py
"""
ê°œì„ ëœ LLM ë³´ì•ˆ ë¶„ì„ê¸°
- LLMì´ ììœ ë¡­ê²Œ ì·¨ì•½ì  ë°œê²¬
- RAGë¡œ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ì œì‹œ
"""
import os
import json
import re
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
from anthropic import Anthropic
from prompts.all_prompts import build_security_analysis_prompt

class ImprovedSecurityAnalyzer:
    """AI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ê¸° - Claude ìš°ì„ """
    
    def __init__(self, use_claude: bool = True):
        """
        Args:
            use_claude: Claudeë¥¼ ìš°ì„  ì‚¬ìš©í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        self.use_claude = use_claude
        self.claude_client = None
        self.openai_client = None
        
        # Claude ì´ˆê¸°í™” (ìš°ì„ ìˆœìœ„ 1)
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                self.claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
                print("âœ… Claude API ì´ˆê¸°í™” ì„±ê³µ (ë©”ì¸ ì—”ì§„)")
            except Exception as e:
                print(f"âš ï¸ Claude ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # OpenAI ì´ˆê¸°í™” (ìš°ì„ ìˆœìœ„ 2 - í´ë°±)
        if os.getenv("OPENAI_API_KEY"):
            try:
                self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                print("âœ… OpenAI API ì´ˆê¸°í™” ì„±ê³µ (í´ë°± ì—”ì§„)")
            except Exception as e:
                print(f"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # API ê°€ìš©ì„± í™•ì¸
        if not self.claude_client and not self.openai_client:
            raise ValueError("âŒ Claudeì™€ OpenAI API ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì„ íƒì )
        self.rag = None
        try:
            from rag.improved_rag_search import ImprovedRAGSearch
            self.rag = ImprovedRAGSearch()
            print("âœ… RAG ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def analyze_security(self, code: str, file_list: List[Dict] = None) -> Dict:
        """ì½”ë“œ ë³´ì•ˆ ë¶„ì„ - ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ """
        
        print("ğŸ” AI ë³´ì•ˆ ë¶„ì„ ì‹œì‘...")
        
        # 1ë‹¨ê³„: AIê°€ ì·¨ì•½ì  ë°œê²¬ ë° ìˆ˜ì • ì½”ë“œ ìƒì„±
        vulnerabilities = self._discover_vulnerabilities(code, file_list)
        
        # ì˜¤ë¥˜ ì²´í¬
        has_error = False
        error_message = ""
        
        if vulnerabilities:
            # íŒŒì‹± ì˜¤ë¥˜ë‚˜ í† í° ì˜¤ë¥˜ ì²´í¬
            for vuln in vulnerabilities:
                if vuln.get('parse_error') or vuln.get('token_error'):
                    has_error = True
                    error_message = vuln.get('description', 'AI ë¶„ì„ ì˜¤ë¥˜')
                    break
        
        if has_error:
            return {
                'success': False,
                'vulnerabilities': vulnerabilities,
                'security_score': 0,
                'summary': f'âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {error_message}',
                'analyzed_by': 'Error',
                'has_error': True,
                'error_type': vulnerabilities[0].get('type', 'Unknown Error')
            }
        
        # ì •ìƒ ì²˜ë¦¬
        if not vulnerabilities:
            return {
                'success': True,
                'vulnerabilities': [],
                'security_score': 100,
                'summary': 'ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'analyzed_by': 'AI',
                'has_error': False
            }
        
        # 2ë‹¨ê³„: RAGë¡œ ê° ì·¨ì•½ì ì— ëŒ€í•œ ê·¼ê±° ì°¾ê¸°
        if self.rag:
            vulnerabilities = self._add_rag_evidence(vulnerabilities)
        
        # 3ë‹¨ê³„: ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°
        security_score = self._calculate_security_score(vulnerabilities)
        
        # 4ë‹¨ê³„: ìš”ì•½ ìƒì„±
        summary = self._generate_summary(vulnerabilities)
        
        return {
            'success': True,
            'vulnerabilities': vulnerabilities,
            'security_score': security_score,
            'summary': summary,
            'analyzed_by': 'Claude' if self.use_claude and self.claude_client else 'GPT',
            'has_error': False
        }
    


    def _discover_vulnerabilities(self, code: str, file_list: List[Dict] = None) -> List[Dict]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì·¨ì•½ì  ë°œê²¬ - use_claude íŒŒë¼ë¯¸í„° ì ìš©"""
        
        prompt = self._build_discovery_prompt(code, file_list)
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ì²˜ìŒ 500ì:\\n{prompt[:500]}\\n")  # í”„ë¡¬í”„íŠ¸ ë‚´ìš© í™•ì¸
        vulnerabilities = []
        
        # use_claude ì„¤ì •ì— ë”°ë¼ ìˆœì„œ ê²°ì •
        if self.use_claude:
            # 1. Claude ìš°ì„  ëª¨ë“œ
            if self.claude_client:
                try:
                    print("ğŸ­ Claude ë¶„ì„ ì‹œì‘ (ìš°ì„  ì—”ì§„)...")
                    vulnerabilities = self._analyze_with_claude(prompt)
                    
                    if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                        print(f"âœ… Claude ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                        return vulnerabilities
                    elif vulnerabilities:
                        print("âš ï¸ Claude íŒŒì‹± ì˜¤ë¥˜, GPTë¡œ í´ë°±")
                except Exception as e:
                    print(f"âš ï¸ Claude ë¶„ì„ ì‹¤íŒ¨: {e}, GPTë¡œ í´ë°±")
            else:
                print("âš ï¸ Claude API ì—†ìŒ, GPTë¡œ ì „í™˜")
            
            # Claude ì‹¤íŒ¨ ì‹œ GPT í´ë°±
            if self.openai_client and not (vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities)):
                try:
                    print("ğŸ¤– GPT ë¶„ì„ ì‹œì‘ (í´ë°±)...")
                    vulnerabilities = self._analyze_with_gpt(prompt)
                    
                    if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                        print(f"âœ… GPT ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                        return vulnerabilities
                except Exception as e:
                    print(f"âŒ GPT ë¶„ì„ë„ ì‹¤íŒ¨: {e}")
        
        else:
            # 2. GPT ì „ìš© ëª¨ë“œ (use_claude=False)
            if self.openai_client:
                try:
                    print("ğŸ¤– GPT ë¶„ì„ ì‹œì‘ (ì „ìš© ëª¨ë“œ)...")
                    vulnerabilities = self._analyze_with_gpt(prompt)
                    
                    if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                        print(f"âœ… GPT ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                        return vulnerabilities
                except Exception as e:
                    print(f"âŒ GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
                    # GPT ì‹¤íŒ¨ ì‹œ Claude ì‹œë„ (ìˆë‹¤ë©´)
                    if self.claude_client:
                        try:
                            print("ğŸ­ Claudeë¡œ ì¬ì‹œë„...")
                            vulnerabilities = self._analyze_with_claude(prompt)
                            
                            if vulnerabilities and not any(v.get('parse_error') for v in vulnerabilities):
                                print(f"âœ… Claude ë¶„ì„ ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
                                return vulnerabilities
                        except Exception as e2:
                            print(f"âŒ Claudeë„ ì‹¤íŒ¨: {e2}")
            else:
                print("âŒ OpenAI API ì—†ìŒ")
        
        # 3. ëª¨ë‘ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜
        if not vulnerabilities:
            vulnerabilities = [{
                "type": "Analysis Failed",
                "severity": "ERROR",
                "confidence": "HIGH",
                "location": {"file": "unknown", "line": 0, "function": "unknown"},
                "description": "AI ë¶„ì„ ì‹¤íŒ¨: ëª¨ë“  AI ì—”ì§„ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                "vulnerable_code": "ë¶„ì„ ë¶ˆê°€",
                "fixed_code": "ë¶„ì„ ë¶ˆê°€",
                "fix_explanation": "API í‚¤ì™€ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "recommendation": "1. .env íŒŒì¼ í™•ì¸\n2. API í¬ë ˆë”§ í™•ì¸\n3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸",
                "parse_error": True
            }]
        
        return vulnerabilities
    
    
    # core/improved_llm_analyzer.py ìˆ˜ì •
    

    def _build_discovery_prompt(self, code: str, file_list: List[Dict] = None) -> str:
        """ì·¨ì•½ì  ë°œê²¬ í”„ë¡¬í”„íŠ¸ - ë¹Œë” í•¨ìˆ˜ í™œìš©"""
        
        file_info = ""
        if file_list:
            file_info = f"\në¶„ì„ ëŒ€ìƒ: {len(file_list)}ê°œ íŒŒì¼\n"
            for f in file_list[:5]:
                file_info += f"- {f['path']} ({f['lines']}ì¤„)\n"

                 # ì½”ë“œ ê¸¸ì´ ì œí•œ
        max_code_length = 25000  # í”„ë¡¬í”„íŠ¸ ê³µê°„ í™•ë³´
        if len(code) > max_code_length:
            code = code[:max_code_length] + "\n# ... (ì½”ë“œê°€ ì˜ë ¸ìŠµë‹ˆë‹¤)"
        
        prompt = f"""Python ë³´ì•ˆ ì „ë¬¸ê°€ë¡œì„œ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

    {file_info}

    ë¶„ì„í•  ì½”ë“œ:
    {code}

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì¸ì‚¬ë§ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:

    {{
        "vulnerabilities": [
            {{
                "type": "ì˜ì–´ë¡œ_ì‘ì„±_í•„ìˆ˜",  // MUST BE IN ENGLISH (e.g., "SQL Injection", "XSS", "Command Injection")
                "severity": "CRITICAL/HIGH/MEDIUM/LOW",
                "confidence": "HIGH/MEDIUM/LOW",
                "location": {{
                    "file": "íŒŒì¼ëª…",
                    "line": ìˆ«ì,
                    "function": "í•¨ìˆ˜ëª…",
                    "code_snippet": "ë¬¸ì œì½”ë“œ"
                }},
                "description": "í•œêµ­ì–´ì„¤ëª…",
                "vulnerable_code": "ì·¨ì•½í•œì½”ë“œ",
                "fixed_code": "ìˆ˜ì •ëœì½”ë“œ",
                "fix_explanation": "ìˆ˜ì •ì„¤ëª…",
                "data_flow": "ë°ì´í„°íë¦„",
                "exploit_scenario": "ê³µê²©ì‹œë‚˜ë¦¬ì˜¤",
                "recommendation": "ê¶Œì¥ì‚¬í•­"
            }}
        ]
    }}

    âš ï¸ ì¤‘ìš” ê·œì¹™:
    - type í•„ë“œëŠ” ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„± (ì˜ˆ: "SQL Injection", "XSS", "Path Traversal", "Command Injection", "Hardcoded Secret")
    - descriptionê³¼ ë‹¤ë¥¸ í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
    - í‘œì¤€ ì˜ì–´ ì·¨ì•½ì  ëª…ì¹­ ì‚¬ìš©:
      * SQL Injection (SQL ì¸ì ì…˜)
      * XSS ë˜ëŠ” Cross-Site Scripting (í¬ë¡œìŠ¤ ì‚¬ì´íŠ¸ ìŠ¤í¬ë¦½íŒ…)  
      * Command Injection (ëª…ë ¹ì–´ ì‚½ì…)
      * Path Traversal (ê²½ë¡œ ì¡°ì‘)
      * Hardcoded Secret (í•˜ë“œì½”ë”©ëœ ì‹œí¬ë¦¿)
      * Weak Cryptography (ì•½í•œ ì•”í˜¸í™”)
      * Insecure Deserialization (ì•ˆì „í•˜ì§€ ì•Šì€ ì—­ì§ë ¬í™”)
      * Information Disclosure (ì •ë³´ ë…¸ì¶œ)
      * Race Condition (ê²½ìŸ ìƒíƒœ)
      * ê¸°íƒ€ ì˜ì–´ í‘œì¤€ ëª…ì¹­

    ì£¼ì˜: JSONë§Œ ì¶œë ¥. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ìŒ."""
    
        return prompt
    
    def _analyze_with_claude(self, prompt: str) -> List[Dict]:
        """Claudeë¡œ ë¶„ì„ - Claude íŠ¹í™” í”„ë¡¬í”„íŠ¸"""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
            model = os.getenv("ANTHROPIC_MODEL")
            if not model:
                model = "claude-3-opus-20240229"
                print(f"âš ï¸ ANTHROPIC_MODEL ë¯¸ì„¤ì •, ê¸°ë³¸ê°’ ì‚¬ìš©: {model}")
            print(f"ëª¨ë¸: {model}")
            print(f"API í‚¤ ì¡´ì¬: {bool(os.getenv('ANTHROPIC_API_KEY'))}")
            # ClaudeëŠ” system roleì´ ì—†ìœ¼ë¯€ë¡œ user ë©”ì‹œì§€ì— í†µí•©
            claude_prompt = """You are a senior security expert analyzing Python code.
    Respond ONLY with valid JSON. No explanations, no markdown.

    """ + prompt
            
            print(f"ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(claude_prompt)}")
            response = self.claude_client.messages.create(
                model=model,
                max_tokens=4000,
                temperature=0.2,
                messages=[
                    {
                        "role": "user",
                        "content": claude_prompt
                    }
                ]
            )
            
            # Claude ì‘ë‹µ ì¶”ì¶œ (content[0].text)
            result_text = response.content[0].text
            
            print(f"ğŸ“ Claude ì‘ë‹µ ê¸¸ì´: {len(result_text)}")
            print(f"ğŸ“ Claude ì‘ë‹µ ì²˜ìŒ 500ì:\\n{result_text[:500]}\\n")
            # ì‘ë‹µ ë¡œê¹…
            print(f"ğŸ“ Claude ì‘ë‹µ ê¸¸ì´: {len(result_text)}")
            if len(result_text) < 50:
                print(f"âš ï¸ ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ: {result_text}")
            
            vulnerabilities = self._parse_json_response(result_text)
            return vulnerabilities
            
        except AttributeError as e:
            # Claude ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ ì²˜ë¦¬
            print(f"âŒ Claude ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {e}")
            if 'response' in locals():
                print(f"ì‘ë‹µ êµ¬ì¡°: {type(response)}")
            raise
        except json.JSONDecodeError as e:
            print(f"âŒ Claude JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_parse_error(str(e), result_text[:500] if 'result_text' in locals() else "")
        except Exception as e:
            print(f"âŒ Claude í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    def _analyze_with_gpt(self, prompt: str) -> List[Dict]:
        """GPTë¡œ ë¶„ì„ - GPT íŠ¹í™” ì„¤ì •"""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
            model = os.getenv("OPENAI_MODEL")
            if not model:
                model = "gpt-4-turbo-preview"
                print(f"âš ï¸ OPENAI_MODEL ë¯¸ì„¤ì •, ê¸°ë³¸ê°’ ì‚¬ìš©: {model}")
            
            # í† í° ê¸¸ì´ ì²´í¬
            prompt_length = len(prompt)
            estimated_tokens = prompt_length // 4
            
            if estimated_tokens > 8000:
                print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ê¹ë‹ˆë‹¤ ({estimated_tokens} í† í° ì˜ˆìƒ)")
            
            # GPTëŠ” response_format ì§€ì› í™•ì¸
            kwargs = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a JSON API that analyzes Python code for vulnerabilities. Respond only with valid JSON. No markdown, no explanations."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.2,
                "max_tokens": 3000
            }
            
            # GPT-4 ëª¨ë¸ë§Œ response_format ì§€ì›
            if "gpt-4" in model:
                kwargs["response_format"] = {"type": "json_object"}
            
            response = self.openai_client.chat.completions.create(**kwargs)
            
            # GPT ì‘ë‹µ ì¶”ì¶œ (choices[0].message.content)
            result_text = response.choices[0].message.content
            
            print(f"ğŸ“ GPT ì‘ë‹µ ê¸¸ì´: {len(result_text)}")
            
            vulnerabilities = self._parse_json_response(result_text)
            return vulnerabilities
            
        except AttributeError as e:
            # GPT ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ ì²˜ë¦¬
            print(f"âŒ GPT ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {e}")
            if 'response' in locals():
                print(f"ì‘ë‹µ êµ¬ì¡°: {type(response)}")
            raise
        except json.JSONDecodeError as e:
            print(f"âŒ GPT JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_parse_error(str(e), result_text[:500] if 'result_text' in locals() else "")
        except Exception as e:
            print(f"âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    def _create_parse_error(self, error_msg: str, response_snippet: str) -> List[Dict]:
        """íŒŒì‹± ì—ëŸ¬ ê°ì²´ ìƒì„±"""
        return [{
            "type": "Parse Error",
            "severity": "ERROR",
            "confidence": "HIGH",
            "location": {"file": "unknown", "line": 0, "function": "parse_error"},
            "description": f"JSON íŒŒì‹± ì‹¤íŒ¨: {error_msg}",
            "vulnerable_code": f"ì‘ë‹µ ì¼ë¶€:\n{response_snippet}",
            "fixed_code": "ì¬ì‹œë„ í•„ìš”",
            "fix_explanation": "AIê°€ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "recommendation": "1. ì½”ë“œë¥¼ ì¤„ì—¬ë³´ì„¸ìš”\n2. ë‹¤ë¥¸ AI ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”\n3. ë‹¤ì‹œ ë¶„ì„ì„ ì‹œë„í•´ë³´ì„¸ìš”",
            "parse_error": True
        }]

    def _parse_json_response(self, response_text: str) -> List[Dict]:
        """ê°•í™”ëœ JSON íŒŒì‹± í•¨ìˆ˜ - ë””ë²„ê¹… í¬í•¨"""
        
        original_text = response_text  # ì›ë³¸ ë³´ì¡´
        
        print(f"ğŸ” ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response_text)} ë¬¸ì")
        print(f"ğŸ” ì‘ë‹µ ì‹œì‘ ë¶€ë¶„: {response_text[:200]}...")
        
        # 1. JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        json_text = None
        
        # ë°©ë²• 1: ```json ë¸”ë¡
        if "```json" in response_text:
            start = response_text.find("```json") + 7
            end = response_text.find("```", start)
            if end > start:
                json_text = response_text[start:end].strip()
                print("âœ… ```json ë¸”ë¡ ë°œê²¬")
        
        # ë°©ë²• 2: ``` ë¸”ë¡
        elif "```" in response_text:
            start = response_text.find("```") + 3
            end = response_text.find("```", start)
            if end > start:
                json_text = response_text[start:end].strip()
                print("âœ… ``` ë¸”ë¡ ë°œê²¬")
        
        # ë°©ë²• 3: ì¤‘ê´„í˜¸ ì°¾ê¸°
        if not json_text and "{" in response_text:
            # ì²« ë²ˆì§¸ { ì°¾ê¸°
            start = response_text.find("{")
            if start >= 0:
                # ë§¤ì¹­ë˜ëŠ” } ì°¾ê¸° (ê°„ë‹¨í•œ ë°©ë²•)
                brace_count = 0
                end = start
                for i in range(start, len(response_text)):
                    if response_text[i] == "{":
                        brace_count += 1
                    elif response_text[i] == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            end = i + 1
                            break
                
                if end > start:
                    json_text = response_text[start:end]
                    print(f"âœ… ì¤‘ê´„í˜¸ ê¸°ë°˜ ì¶”ì¶œ: {start}:{end}")
        
        # JSONì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‹œë„
        if not json_text:
            json_text = response_text.strip()
            print("âš ï¸ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì „ì²´ í…ìŠ¤íŠ¸ ì‹œë„")
        
        # 2. íŒŒì‹± ì „ ì •ë¦¬
        json_text = self._clean_json_text(json_text)
        
        print(f"ğŸ” ì •ë¦¬ëœ JSON ì‹œì‘: {json_text[:100]}...")
        
        # 3. íŒŒì‹± ì‹œë„
        try:
            result = json.loads(json_text)

            # ê²°ê³¼ í˜•íƒœ ìœ ì—° ì²˜ë¦¬: dict | list ëª¨ë‘ ì§€ì›
            vulnerabilities = []
            if isinstance(result, list):
                # LLMì´ ë°”ë¡œ ì·¨ì•½ì  ë°°ì—´ì„ ë°˜í™˜í•œ ê²½ìš°
                vulnerabilities = result
            elif isinstance(result, dict):
                # í‘œì¤€ ìŠ¤í‚¤ë§ˆ
                if 'vulnerabilities' in result and isinstance(result['vulnerabilities'], list):
                    vulnerabilities = result['vulnerabilities']
                # ëŒ€ì²´ ìŠ¤í‚¤ë§ˆ(analysis.code_vulnerabilities ë˜ëŠ” analysis.vulnerabilities)
                elif isinstance(result.get('analysis'), dict):
                    analysis_obj = result['analysis']
                    if isinstance(analysis_obj.get('code_vulnerabilities'), list):
                        vulnerabilities = analysis_obj['code_vulnerabilities']
                    elif isinstance(analysis_obj.get('vulnerabilities'), list):
                        vulnerabilities = analysis_obj['vulnerabilities']
                # ë‹¨ì¼ ì·¨ì•½ì  ê°ì²´ë¥¼ ë°˜í™˜í•œ ê²½ìš°
                elif all(k in result for k in ['type', 'severity']):
                    vulnerabilities = [result]

            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {len(vulnerabilities)}ê°œ ì·¨ì•½ì ")
            return vulnerabilities
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"âŒ ë¬¸ì œ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
            
            # ë¬¸ì œ ë¶€ë¶„ ì¶œë ¥
            lines = json_text.split('\n')
            if e.lineno <= len(lines):
                print(f"âŒ ë¬¸ì œ ë¼ì¸: {lines[e.lineno-1]}")
            
            # ë§ˆì§€ë§‰ ì‹œë„: ë” ê³µê²©ì ì¸ ì •ë¦¬
            try:
                json_text = self._aggressive_clean(original_text)
                result = json.loads(json_text)
                print("âœ… ê³µê²©ì  ì •ë¦¬ í›„ íŒŒì‹± ì„±ê³µ")
                return result.get('vulnerabilities', [])
            except:
                # ì™„ì „ ì‹¤íŒ¨
                raise e

    def _clean_json_text(self, text: str) -> str:
        """JSON í…ìŠ¤íŠ¸ ì •ë¦¬"""
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        # BOM ì œê±°
        if text.startswith('\ufeff'):
            text = text[1:]
        
        # ì¼ë°˜ì ì¸ ì ‘ë‘ì‚¬ ì œê±°
        prefixes = [
            "Here is the JSON response:",
            "Here's the analysis:",
            "JSON:",
            "```json",
            "```"
        ]
        
        for prefix in prefixes:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
        
        # ì¼ë°˜ì ì¸ ì ‘ë¯¸ì‚¬ ì œê±°
        suffixes = [
            "```",
            "I hope this helps!",
            "Let me know if you need",
        ]
        
        for suffix in suffixes:
            if text.endswith(suffix):
                text = text[:-len(suffix)].strip()
        
        return text

    def _aggressive_clean(self, text: str) -> str:
        """ê³µê²©ì ì¸ JSON ì¶”ì¶œ (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        import re
        
        # ëª¨ë“  ê°€ëŠ¥í•œ JSON íŒ¨í„´ ì°¾ê¸°
        patterns = [
            r'\{[\s\S]*"vulnerabilities"[\s\S]*\}',  # vulnerabilitiesë¥¼ í¬í•¨í•˜ëŠ” JSON
            r'\{[^{}]*\{[^{}]*\}[^{}]*\}',  # ì¤‘ì²©ëœ ê°ì²´
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            if matches:
                # ê°€ì¥ ê¸´ ë§¤ì¹˜ ì„ íƒ
                longest = max(matches, key=len)
                try:
                    # í…ŒìŠ¤íŠ¸ íŒŒì‹±
                    json.loads(longest)
                    print(f"âœ… ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ JSON ì¶”ì¶œ ì„±ê³µ")
                    return longest
                except:
                    continue
        
        # ì‹¤íŒ¨
        return text

    def _fix_common_json_errors(self, text: str) -> str:
        """ì¼ë°˜ì ì¸ JSON ì˜¤ë¥˜ ìˆ˜ì •"""
        
        # ì¤„ë°”ê¿ˆ ì²˜ë¦¬
        text = text.replace('\n', '\\n')
        text = text.replace('\r', '\\r')
        text = text.replace('\t', '\\t')
        
        # ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
        # ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ëœ ê²ƒì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        text = text.replace('\\\\', '__DOUBLE_BACKSLASH__')
        text = text.replace('\\"', '__ESCAPED_QUOTE__')
        
        # JSON ë‚´ë¶€ì˜ ë”°ì˜´í‘œ ì²˜ë¦¬ (ë§¤ìš° ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ)
        # ... ë³µì¡í•œ ë¡œì§ í•„ìš”
        
        # ì„ì‹œ ì¹˜í™˜ ë³µì›
        text = text.replace('__ESCAPED_QUOTE__', '\\"')
        text = text.replace('__DOUBLE_BACKSLASH__', '\\\\')
        
        # ë§ë¯¸ ì‰¼í‘œ ì œê±°
        text = re.sub(r',\s*}', '}', text)
        text = re.sub(r',\s*]', ']', text)
        
        return text

    def _aggressive_json_fix(self, text: str) -> str:
        """ë” ê³µê²©ì ì¸ JSON ìˆ˜ì • (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        import re
        
        # ëª¨ë“  ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        text = ' '.join(text.split())
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ë¬¸ìì—´ ë‚´ë¶€ì˜ ë”°ì˜´í‘œ ì²˜ë¦¬
        # "key": "value with "quotes" inside" -> "key": "value with \"quotes\" inside"
        # ì´ê²ƒì€ ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ ê²½ìš°ë§Œ ì²˜ë¦¬
        
        return text
        
    
    # core/improved_llm_analyzer.py


    # core/improved_llm_analyzer.py
# _add_rag_evidence ë©”ì„œë“œ ì „ì²´ êµì²´

    # core/improved_llm_analyzer.py
# _add_rag_evidence ë©”ì„œë“œ ìˆ˜ì • - ì½”ë“œ ë¶€ë¶„ ì œê±°

    # core/improved_llm_analyzer.py

    def _add_rag_evidence(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """ê° ì·¨ì•½ì ì— RAG ê·¼ê±° ì¶”ê°€ - ê°œì„ ëœ ë²„ì „"""
        if not self.rag:
            return vulnerabilities
        
        print("ğŸ“š RAGë¡œ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ì°¾ëŠ” ì¤‘...")
        
        for vuln in vulnerabilities:
            vuln_type = vuln.get('type', '')
            if not vuln_type:
                continue

            # 1. ê°œì„ ëœ RAG ê²€ìƒ‰ ì‹¤í–‰
            # search_vulnerability_evidenceê°€ ë§¤í•‘ê³¼ ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ ëª¨ë‘ ì²˜ë¦¬
            results = self.rag.search_vulnerability_evidence(vuln_type)
            
            # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            if results and results.get('vulnerability'):
                vuln_data = results['vulnerability']
                metadata = vuln_data.get('metadata', {})
                
                # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ ë° í¬ë§·íŒ…
                page_info = "ì•Œ ìˆ˜ ì—†ìŒ"
                start_page = metadata.get('start_page')
                end_page = metadata.get('end_page')

                if start_page and end_page:
                    if start_page != end_page:
                        page_info = f"{start_page}-{end_page}"
                    else:
                        page_info = str(start_page)
                
                # evidence ê°ì²´ ìƒì„±
                vuln['evidence'] = {
                    'source': 'KISIA ê°€ì´ë“œë¼ì¸',
                    'document': 'Python_ì‹œíì–´ì½”ë”©_ê°€ì´ë“œ(2023ë…„_ê°œì •ë³¸).pdf',
                    'page': page_info,
                    'section_title': metadata.get('korean_name', ''),
                    'content': vuln_data.get('content', '')[:500] + "...", # ë‚´ìš©ì€ í•„ìš”í•œ ë§Œí¼ ì¡°ì ˆ
                    'full_content': vuln_data.get('content', '')
                }
                print(f"  âœ“ '{vuln_type}' â†’ '{metadata.get('korean_name')}' ê·¼ê±° ì°¾ìŒ (í˜ì´ì§€: {page_info})")
            else:
                print(f"  âŒ '{vuln_type}'ì— ëŒ€í•œ ê°€ì´ë“œë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

        return vulnerabilities

    def _extract_description_only(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì½”ë“œ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì„¤ëª…ë§Œ ì¶”ì¶œ"""
        lines = text.split('\n')
        cleaned_lines = []
        in_code_block = False
        
        for line in lines:
            # ì½”ë“œ ë¸”ë¡ ì‹œì‘/ë í‘œì‹œ ê°ì§€
            if any(marker in line for marker in [
                '[ì•ˆì „í•˜ì§€ ì•Šì€ ì½”ë“œ]', '[ì•ˆì „í•œ ì½”ë“œ]', 
                'ì•ˆì „í•˜ì§€ ì•Šì€ ì½”ë“œ ì˜ˆì‹œ', 'ì•ˆì „í•œ ì½”ë“œ ì˜ˆì‹œ',
                '```python', '```', 'def ', 'class ', 'import '
            ]):
                in_code_block = True
                continue
            
            # ì½”ë“œ ë¼ì¸ ë²ˆí˜¸ íŒ¨í„´ (ì˜ˆ: "1:", "2:" ë“±)
            if re.match(r'^\d+:', line.strip()):
                in_code_block = True
                continue
            
            # ê¶Œì¥ì‚¬í•­ì´ë‚˜ ì„¤ëª… ì„¹ì…˜ ì‹œì‘
            if any(marker in line for marker in ['[ê¶Œì¥ì‚¬í•­]', '[ì„¤ëª…]', '[ì·¨ì•½ì ']):
                in_code_block = False
            
            # ì½”ë“œ ë¸”ë¡ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
            if not in_code_block and line.strip():
                # ì¶”ê°€ í•„í„°ë§: ì½”ë“œì²˜ëŸ¼ ë³´ì´ëŠ” ë¼ì¸ ì œì™¸
                if not any(pattern in line for pattern in ['__', 'self.', '()', '{}', '[]', '= ']):
                    cleaned_lines.append(line.strip())
        
        # ì—°ì†ëœ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        cleaned_text = ' '.join(cleaned_lines)
        
        # ì¤‘ë³µ ê³µë°± ì œê±°
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
        
        # ì„¹ì…˜ ì œëª©ê³¼ ì„¤ëª… ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if '[ì„¤ëª…]' in cleaned_text:
            parts = cleaned_text.split('[ì„¤ëª…]')
            if len(parts) > 1:
                cleaned_text = parts[1].split('[')[0].strip()
        
        return cleaned_text

    def _extract_keywords_from_description(self, description: str) -> List[str]:
        """ì„¤ëª…ì—ì„œ ë³´ì•ˆ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ë³´ì•ˆ ê´€ë ¨ ì¤‘ìš” í‚¤ì›Œë“œ
        security_terms = [
            'ì•”í˜¸í™”', 'í•´ì‹œ', 'íŒ¨ìŠ¤ì›Œë“œ', 'ë¹„ë°€ë²ˆí˜¸', 'ì‹œí¬ë¦¿', 'secret', 'key',
            'SQL', 'XSS', 'CSRF', 'ì¸ì ì…˜', 'injection', 'ì„¸ì…˜', 'session',
            'ì¸ì¦', 'ì¸ê°€', 'authentication', 'authorization', 'í† í°', 'token',
            'íŒŒì¼', 'file', 'ê²½ë¡œ', 'path', 'ëª…ë ¹ì–´', 'command', 'os',
            'ì§ë ¬í™”', 'serialize', 'pickle', 'yaml', 'eval', 'exec'
        ]
        
        description_lower = description.lower()
        for term in security_terms:
            if term.lower() in description_lower:
                keywords.append(term)
                if len(keywords) >= 3:  # ìµœëŒ€ 3ê°œ
                    break
        
        return keywords

    def _find_most_relevant_document(self, documents: List[str], metadatas: List[Dict], 
                                    vuln_type: str, standard_type: str) -> Optional[int]:
        """ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ì¸ë±ìŠ¤ ì°¾ê¸°"""
        if not documents:
            return None
        
        best_score = -1
        best_idx = 0
        
        for i, (doc, meta) in enumerate(zip(documents, metadatas if metadatas else [{}]*len(documents))):
            score = 0
            
            # 1. ë©”íƒ€ë°ì´í„°ì˜ vulnerability_types í™•ì¸
            if meta and 'vulnerability_types' in meta:
                doc_vuln_types = meta['vulnerability_types'].lower()
                if standard_type.lower() in doc_vuln_types:
                    score += 3  # ì •í™•í•œ íƒ€ì… ë§¤ì¹­
                elif vuln_type.lower() in doc_vuln_types:
                    score += 2  # ì›ë³¸ íƒ€ì… ë§¤ì¹­
            
            # 2. ë¬¸ì„œ ë‚´ìš©ì— ì·¨ì•½ì  íƒ€ì… ì–¸ê¸‰ í™•ì¸
            doc_lower = doc.lower()
            if vuln_type.lower() in doc_lower:
                score += 1
            
            # 3. íŠ¹ì • í‚¤ì›Œë“œ ë§¤ì¹­ (ì·¨ì•½ì ë³„)
            if 'hardcoded' in vuln_type.lower() or 'secret' in vuln_type.lower():
                if any(word in doc_lower for word in ['í™˜ê²½ë³€ìˆ˜', 'í™˜ê²½ ë³€ìˆ˜', 'environment', 'env', 'í•˜ë“œì½”ë”©', 'ë…¸ì¶œ']):
                    score += 2
                if any(word in doc_lower for word in ['rsa', 'ì•”í˜¸í™” í‚¤', 'ëŒ€ì¹­í‚¤']):
                    score -= 1  # RSA ê´€ë ¨ ë‚´ìš©ì€ ê°ì  (Hardcoded Secretê³¼ ê´€ë ¨ ë‚®ìŒ)
            
            elif 'sql' in vuln_type.lower():
                if any(word in doc_lower for word in ['íŒŒë¼ë¯¸í„°', 'parameter', 'ë°”ì¸ë”©', 'binding', 'prepared']):
                    score += 2
            
            elif 'xss' in vuln_type.lower():
                if any(word in doc_lower for word in ['ì´ìŠ¤ì¼€ì´í”„', 'escape', 'sanitize', 'ì‚­ì œ', 'html']):
                    score += 2
            
            if score > best_score:
                best_score = score
                best_idx = i
        
        # ìµœì†Œ ì ìˆ˜ ë¯¸ë‹¬ì‹œ None ë°˜í™˜
        if best_score < 1:
            return None
        
        return best_idx

    def _calculate_relevance_score(self, content: str, vuln_type: str, description: str) -> float:
        """ì»¨í…ì¸ ì™€ ì·¨ì•½ì  ê°„ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (0~1)"""
        score = 0.0
        content_lower = content.lower()
        
        # 1. ì·¨ì•½ì  íƒ€ì… ì–¸ê¸‰ í™•ì¸ (30%)
        if vuln_type.lower() in content_lower:
            score += 0.3
        
        # 2. ì·¨ì•½ì ë³„ íŠ¹ì • í‚¤ì›Œë“œ í™•ì¸ (50%)
        keyword_score = 0.0
        
        if 'hardcoded' in vuln_type.lower() or 'secret' in vuln_type.lower():
            keywords = ['í™˜ê²½ë³€ìˆ˜', 'í™˜ê²½ ë³€ìˆ˜', 'environment', '.env', 'config', 'ì„¤ì • íŒŒì¼', 'í•˜ë“œì½”ë”©']
            matches = sum(1 for k in keywords if k in content_lower)
            keyword_score = min(matches * 0.1, 0.5)
        
        elif 'sql' in vuln_type.lower() or 'injection' in vuln_type.lower():
            keywords = ['íŒŒë¼ë¯¸í„°', 'parameter', 'ë°”ì¸ë”©', 'binding', 'prepared', 'statement', '?', '%s']
            matches = sum(1 for k in keywords if k in content_lower)
            keyword_score = min(matches * 0.1, 0.5)
        
        elif 'xss' in vuln_type.lower():
            keywords = ['ì´ìŠ¤ì¼€ì´í”„', 'escape', 'sanitize', 'ì‚­ì œ', 'html', 'script', 'ìŠ¤í¬ë¦½íŠ¸']
            matches = sum(1 for k in keywords if k in content_lower)
            keyword_score = min(matches * 0.1, 0.5)
        
        else:
            # ì¼ë°˜ì ì¸ ë³´ì•ˆ í‚¤ì›Œë“œ
            keywords = ['ì·¨ì•½', 'ê³µê²©', 'ë°©ì–´', 'ë³´ì•ˆ', 'ì•ˆì „', 'ìœ„í—˜', 'ê²€ì¦', 'í™•ì¸']
            matches = sum(1 for k in keywords if k in content_lower)
            keyword_score = min(matches * 0.08, 0.5)
        
        score += keyword_score
        
        # 3. ì„¤ëª…ê³¼ì˜ ìœ ì‚¬ì„± (20%)
        if description:
            desc_words = set(description.lower().split())
            content_words = set(content_lower.split())
            if desc_words and content_words:
                intersection = desc_words & content_words
                similarity = len(intersection) / min(len(desc_words), 20)  # ìµœëŒ€ 20ë‹¨ì–´ ë¹„êµ
                score += min(similarity * 0.2, 0.2)
        
        return min(score, 1.0)
        
    def _calculate_security_score(self, vulnerabilities: List[Dict]) -> int:
        """ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°"""
        if not vulnerabilities:
            return 100
        
        score = 100
        
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'MEDIUM')
            confidence = vuln.get('confidence', 'MEDIUM')
            
            # ì‹¬ê°ë„ë³„ ê°ì  (ì™„í™”ëœ ê¸°ì¤€)
            severity_penalty = {
                'CRITICAL': 24,
                'HIGH': 14,
                'MEDIUM': 6,
                'LOW': 2
            }.get(severity, 6)
            
            # í™•ì‹ ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            confidence_weight = {
                'HIGH': 1.0,
                'MEDIUM': 0.7,
                'LOW': 0.4
            }.get(confidence, 0.7)
            
            score -= int(severity_penalty * confidence_weight)
        
        return max(0, score)
    
    def _generate_summary(self, vulnerabilities: List[Dict]) -> str:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""
        if not vulnerabilities:
            return "ì½”ë“œ ë¶„ì„ ê²°ê³¼ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        total = len(vulnerabilities)
        critical = sum(1 for v in vulnerabilities if v.get('severity') == 'CRITICAL')
        high = sum(1 for v in vulnerabilities if v.get('severity') == 'HIGH')
        
        summary = f"ì´ {total}ê°œì˜ ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        
        if critical > 0:
            summary += f" (CRITICAL: {critical}ê°œ)"
        if high > 0:
            summary += f" (HIGH: {high}ê°œ)"
        
        # ì£¼ìš” ì·¨ì•½ì  íƒ€ì…
        vuln_types = list(set(v.get('type', 'Unknown') for v in vulnerabilities))
        if vuln_types:
            summary += f". ì£¼ìš” ìœ í˜•: {', '.join(vuln_types[:3])}"
        
        return summary


# ê°„ë‹¨í•œ ì‚¬ìš© í—¬í¼ í•¨ìˆ˜
def analyze_code_with_ai(code: str, file_list: List[Dict] = None, use_claude: bool = True) -> Dict:
    """
    ì½”ë“œë¥¼ AIë¡œ ë¶„ì„í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        code: ë¶„ì„í•  Python ì½”ë“œ
        file_list: íŒŒì¼ ëª©ë¡
        use_claude: Claude ìš°ì„  ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    analyzer = ImprovedSecurityAnalyzer(use_claude=use_claude)
    return analyzer.analyze_security(code, file_list)