# rag/simple_rag.py
# ì „ì²´ íŒŒì¼ êµì²´

import os
from typing import List, Dict
from openai import OpenAI
from prompts.all_prompts import RAG_PROMPTS, SYSTEM_PROMPTS

class SimpleRAG:
    def __init__(self):
        self.collection = None
        self.chroma_available = False
        
        # ChromaDB ë¡œë“œ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        try:
            import chromadb
            self.chroma_client = chromadb.PersistentClient(path="data/vector_db")
            
            try:
                self.collection = self.chroma_client.get_collection("kisia_vulnerabilities")
                self.chroma_available = True
                print(f"âœ… ë²¡í„° DB ë¡œë“œ ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {self.collection.count()})")
            except Exception as e:
                print(f"âš ï¸ ChromaDB Collection ì—†ìŒ: {e}")
                print("RAG ì—†ì´ ì¼ë°˜ Q&A ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        except ImportError:
            print("âš ï¸ ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ Q&A ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=api_key)
        
    # rag/simple_rag.py
# search_similar ë©”ì„œë“œ ìˆ˜ì •

    def search_similar(self, query: str, top_k: int = 5, filter_metadata: Dict = None) -> Dict:
        """ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ - ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¶”ê°€"""
        if self.chroma_available and self.collection:
            try:
                # ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±
                where_clause = None
                if filter_metadata:
                    where_clause = filter_metadata
                
                # ChromaDB ì¿¼ë¦¬ ì‹¤í–‰
                if where_clause:
                    results = self.collection.query(
                        query_texts=[query],
                        n_results=top_k,
                        where=where_clause  # ë©”íƒ€ë°ì´í„° í•„í„° ì¶”ê°€
                    )
                else:
                    results = self.collection.query(
                        query_texts=[query],
                        n_results=top_k
                    )
                
                # ì»¬ë ‰ì…˜ ì´ë¦„ ì¶”ê°€
                results['collection_name'] = self.collection.name if hasattr(self.collection, 'name') else 'unknown'
                return results
                
            except Exception as e:
                print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                return {'documents': [[]], 'metadatas': [[]], 'collection_name': 'error'}
        else:
            return {'documents': [[]], 'metadatas': [[]], 'collection_name': 'none'}


# rag/simple_rag.py
# ask() í•¨ìˆ˜ ì „ì²´ êµì²´

    # rag/simple_rag.py
    # ask() í•¨ìˆ˜ ìˆ˜ì •

    def ask(self, question: str) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± - ì™„ì „í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ"""
        
        from prompts.all_prompts import RAG_PROMPTS, SYSTEM_PROMPTS
        import streamlit as st
        import time
        
        # 1. ì™„ì „í•œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (í•¨ìˆ˜ëª… ìˆ˜ì •)
        context = {
            'analysis_info': self._get_analysis_info(),
            'vulnerabilities_detail': self._get_vulnerabilities_detail(),
            'code_context': self._get_code_context(),
            'sbom_info': self._get_sbom_info(),
            'conversation_history': self._get_full_conversation_history()
        }
        
        # 2. RAG ê²€ìƒ‰ (ì„ íƒì , ë¹ ë¥´ê²Œ)
        rag_note = ""
        rag_metadata = None
        
        if self.chroma_available:
            try:
                start_time = time.time()
                search_results = self.search_similar(question, top_k=3)
                
                if time.time() - start_time < 1.0 and search_results['documents'][0]:
                    docs = search_results['documents'][0]
                    metadatas = search_results.get('metadatas', [[]])[0]
                    
                    # ì¶œì²˜ ì •ë³´ êµ¬ì„±
                    source_info = []
                    for i, (doc, meta) in enumerate(zip(docs[:2], metadatas[:2])):
                        if meta:
                            page = meta.get('page', '?')
                            page_start = meta.get('page_start', page)
                            page_end = meta.get('page_end', page)
                            
                            if page_start and page_end and page_start != page_end:
                                page_range = f"p.{page_start}-{page_end}"
                            else:
                                page_range = f"p.{page}"
                            
                            source_info.append({
                                'page_range': page_range,
                                'title': meta.get('title', ''),
                                'type': meta.get('type', ''),
                                'vulnerability_types': meta.get('vulnerability_types', '')
                            })
                    
                    rag_context = "\n".join(docs[:2])
                    rag_note = f"\n\n[KISIA ê°€ì´ë“œë¼ì¸ ì°¸ê³ ]\n{rag_context}"
                    
                    # ë©”íƒ€ë°ì´í„° ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©)
                    rag_metadata = source_info
                    
                    print(f"âœ… RAG ë¬¸ì„œ ë°œê²¬ ({len(docs)}ê°œ)")
            except Exception as e:
                print(f"âš ï¸ RAG ê²€ìƒ‰ ìŠ¤í‚µ: {e}")
        
        # 3. ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëª¨ë“  ì •ë³´ í¬í•¨)
        prompt = RAG_PROMPTS["qa_smart_context"].format(
            analysis_info=context['analysis_info'],
            vulnerabilities_detail=context['vulnerabilities_detail'],
            code_context=context['code_context'],
            sbom_info=context['sbom_info'],
            conversation_history=context['conversation_history'],
            question=question,
            rag_note=rag_note
        )
        
        # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì²´í¬
        prompt_length = len(prompt)
        if prompt_length > 30000:  # ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ ì¶•ì†Œ
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹€ ({prompt_length}ì), ì¼ë¶€ ì¶•ì†Œ")
            # ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¤„ì„
            context['code_context'] = context['code_context'][:5000] + "\n... (ìƒëµ) ..."
            prompt = RAG_PROMPTS["qa_smart_context"].format(
                analysis_info=context['analysis_info'],
                vulnerabilities_detail=context['vulnerabilities_detail'],
                code_context=context['code_context'],
                sbom_info=context['sbom_info'],
                conversation_history=context['conversation_history'][-5000:],  # ëŒ€í™”ë„ ì¶•ì†Œ
                question=question,
                rag_note=rag_note
            )
        
        # 4. AI ë‹µë³€ ìƒì„±
        answer = self._generate_ai_answer(prompt)
        
        # 5. ì¶œì²˜ í‘œì‹œ (ë” ìƒì„¸í•˜ê²Œ)
        if answer:
            footer_parts = ["\n\n---"]
            
            # RAG ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìƒì„¸ ì¶œì²˜ í‘œì‹œ
            if rag_metadata:
                footer_parts.append("\n**ğŸ“š ì°¸ê³  ë¬¸ì„œ:**")
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ë¬¸ì„œëª… ì¶”ì¶œ
                used_docs = set()
                for source in rag_metadata:
                    doc_name = source.get('source_document', 'Python_ì‹œíì–´ì½”ë”©_ê°€ì´ë“œ(2023ë…„_ê°œì •ë³¸).pdf')
                    used_docs.add(doc_name)

                for doc in used_docs:
                    footer_parts.append(f"*{doc}*")
                
                for source in rag_metadata:
                    if source['page_range']:
                        footer_parts.append(f"â€¢ {source['page_range']}")
                        if source['title']:
                            footer_parts.append(f"  - {source['title']}")
                        if source['vulnerability_types']:
                            footer_parts.append(f"  - ê´€ë ¨: {source['vulnerability_types']}")
            
            elif rag_note:
                footer_parts.append("*ğŸ“š KISIA ê°€ì´ë“œë¼ì¸ ì°¸ì¡°*")
            
            if "ì´ì „ ëŒ€í™”" in context['conversation_history'] and len(context['conversation_history']) > 50:
                footer_parts.append("*ğŸ’¬ ëŒ€í™” ë§¥ë½ ìœ ì§€*")
            
            if len(footer_parts) == 1:  # íŠ¹ë³„í•œ ì°¸ì¡° ì—†ìŒ
                footer_parts.append("*ğŸ’¡ ì¼ë°˜ ë³´ì•ˆ ì§€ì‹ ê¸°ë°˜*")
            
            return answer + "\n".join(footer_parts)
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def get_stats(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´"""
        if self.chroma_available and self.collection:
            return {
                "mode": "RAG ëª¨ë“œ",
                "total_documents": self.collection.count(),
                "collection_name": "secure_coding_guide",
                "status": "ì •ìƒ"
            }
        else:
            return {
                "mode": "ì¼ë°˜ Q&A ëª¨ë“œ",
                "total_documents": 0,
                "collection_name": "ì—†ìŒ",
                "status": "RAG ì—†ì´ ì‘ë™ ì¤‘"
            }
        
# rag/simple_rag.py
# ìƒˆë¡œìš´ í—¬í¼ í•¨ìˆ˜ë“¤ ì¶”ê°€

    def _gather_complete_context(self) -> dict:
        """ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì™„ì „í•˜ê²Œ ìˆ˜ì§‘"""
        import streamlit as st
        
        return {
            'analysis_info': self._get_analysis_info(),
            'vulnerabilities_detail': self._get_vulnerabilities_detail(),
            'code_context': self._get_code_context(),
            'sbom_info': self._get_sbom_info(),
            'conversation_history': self._get_full_conversation_history()
        }

    def _get_analysis_info(self) -> str:
        """ë¶„ì„ ë©”íƒ€ë°ì´í„° ì •ë³´"""
        import streamlit as st
        
        analysis_results = st.session_state.get('analysis_results', {})
        if not analysis_results:
            return "ì•„ì§ ì½”ë“œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        info_parts = []
        
        # ê¸°ë³¸ ì •ë³´
        info_parts.append(f"ë¶„ì„ ì™„ë£Œ ì‹œê°„: {analysis_results.get('analysis_time', 0):.1f}ì´ˆ ì „")
        info_parts.append(f"ë¶„ì„í•œ íŒŒì¼ ìˆ˜: {analysis_results.get('analyzed_files', 0)}ê°œ")
        
        # ë¶„ì„ ëª¨ë“œ
        mode = st.session_state.get('analysis_mode', 'ì•Œ ìˆ˜ ì—†ìŒ')
        info_parts.append(f"ë¶„ì„ ëª¨ë“œ: {mode}")
        
        # AI ì—”ì§„
        if 'ai_analysis' in analysis_results:
            ai_result = analysis_results['ai_analysis']
            info_parts.append(f"AI ì—”ì§„: {ai_result.get('analyzed_by', 'Unknown')}")
            info_parts.append(f"ë³´ì•ˆ ì ìˆ˜: {ai_result.get('security_score', 100)}/100")
            info_parts.append(f"ë°œê²¬ëœ ì·¨ì•½ì : {len(ai_result.get('vulnerabilities', []))}ê°œ")
        
        # íŒŒì¼ ëª©ë¡
        if 'analysis_file_list' in st.session_state:
            files = st.session_state.analysis_file_list
            info_parts.append(f"\në¶„ì„í•œ íŒŒì¼ ëª©ë¡:")
            for f in files:
                info_parts.append(f"  - {f['path']} ({f['lines']}ì¤„, {f['size']}ë°”ì´íŠ¸)")
        
        return "\n".join(info_parts)

    def _get_vulnerabilities_detail(self) -> str:
        """ëª¨ë“  ì·¨ì•½ì ì˜ ì™„ì „í•œ ì •ë³´"""
        import streamlit as st
        import json
        
        analysis_results = st.session_state.get('analysis_results', {})
        if not analysis_results or 'ai_analysis' not in analysis_results:
            return "ì·¨ì•½ì  ì •ë³´ ì—†ìŒ"
        
        vulnerabilities = analysis_results['ai_analysis'].get('vulnerabilities', [])
        if not vulnerabilities:
            return "ë°œê²¬ëœ ì·¨ì•½ì  ì—†ìŒ"
        
        vuln_details = []
        
        for i, vuln in enumerate(vulnerabilities, 1):
            vuln_details.append(f"\n[ì·¨ì•½ì  {i}]")
            vuln_details.append(f"íƒ€ì…: {vuln.get('type', 'Unknown')}")
            vuln_details.append(f"ì‹¬ê°ë„: {vuln.get('severity', 'UNKNOWN')}")
            vuln_details.append(f"ì‹ ë¢°ë„: {vuln.get('confidence', 'UNKNOWN')}")
            
            # ìœ„ì¹˜ ì •ë³´
            location = vuln.get('location', {})
            vuln_details.append(f"íŒŒì¼: {location.get('file', 'unknown')}")
            vuln_details.append(f"ë¼ì¸: {location.get('line', '?')}")
            vuln_details.append(f"í•¨ìˆ˜: {location.get('function', 'unknown')}")
            
            # ì„¤ëª…
            vuln_details.append(f"ì„¤ëª…: {vuln.get('description', 'ì„¤ëª… ì—†ìŒ')}")
            
            # ì·¨ì•½í•œ ì½”ë“œ
            if vuln.get('vulnerable_code'):
                vuln_details.append(f"ì·¨ì•½í•œ ì½”ë“œ:\n```python\n{vuln['vulnerable_code']}\n```")
            
            # ìˆ˜ì •ëœ ì½”ë“œ (ì¤‘ìš”!)
            if vuln.get('fixed_code'):
                vuln_details.append(f"ìˆ˜ì • ì½”ë“œ:\n```python\n{vuln['fixed_code']}\n```")
            
            # ìˆ˜ì • ì„¤ëª…
            if vuln.get('fix_explanation'):
                vuln_details.append(f"ìˆ˜ì • ì„¤ëª…: {vuln['fix_explanation']}")
            
            # ê¶Œì¥ì‚¬í•­
            if vuln.get('recommendation'):
                vuln_details.append(f"ê¶Œì¥ì‚¬í•­: {vuln['recommendation']}")
            
            vuln_details.append("-" * 40)
        
        return "\n".join(vuln_details)

    def _get_code_context(self) -> str:
        """ë¶„ì„í•œ ì½”ë“œì˜ ì¼ë¶€ ì œê³µ"""
        import streamlit as st
        
        # ë¶„ì„í•œ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        analysis_code = st.session_state.get('analysis_code', '')
        if not analysis_code:
            return "ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ"
        
        # ë„ˆë¬´ ê¸¸ë©´ ì£¼ìš” ë¶€ë¶„ë§Œ
        max_length = 3000
        if len(analysis_code) > max_length:
            # ì²˜ìŒ ë¶€ë¶„ê³¼ ì·¨ì•½ì  ê´€ë ¨ ë¶€ë¶„ í¬í•¨
            code_preview = analysis_code[:max_length] + "\n... (ì½”ë“œ ìƒëµ) ..."
        else:
            code_preview = analysis_code
        
        # íŒŒì¼ë³„ë¡œ êµ¬ë¶„ëœ ê²½ìš° í‘œì‹œ
        if "# ===== File:" in code_preview:
            return f"ë¶„ì„í•œ ì½”ë“œ (ì¼ë¶€):\n\n{code_preview}"
        else:
            return f"ë¶„ì„í•œ ì½”ë“œ:\n```python\n{code_preview}\n```"

    def _get_sbom_info(self) -> str:
        """SBOM ì •ë³´ ì œê³µ"""
        import streamlit as st
        
        analysis_results = st.session_state.get('analysis_results', {})
        if 'sbom' not in analysis_results:
            return "SBOM ì •ë³´ ì—†ìŒ"
        
        sbom = analysis_results['sbom']
        packages = sbom.get('packages', [])
        
        if not packages:
            return "ë°œê²¬ëœ íŒ¨í‚¤ì§€ ì—†ìŒ"
        
        sbom_parts = []
        sbom_parts.append(f"ì´ {len(packages)}ê°œ ì™¸ë¶€ íŒ¨í‚¤ì§€ ì‚¬ìš©")
        sbom_parts.append("\níŒ¨í‚¤ì§€ ëª©ë¡:")
        
        for pkg in packages:
            name = pkg.get('name', 'unknown')
            version = pkg.get('version') or pkg.get('actual_version') or 'ë²„ì „ ì—†ìŒ'
            status = pkg.get('status', '')
            
            sbom_parts.append(f"  - {name}: {version} {status}")
            
            # ì¢…ì†ì„± ì •ë³´
            if pkg.get('dependencies'):
                deps_count = pkg.get('dependencies_count', len(pkg['dependencies']))
                sbom_parts.append(f"    â†’ {deps_count}ê°œ ì¢…ì†ì„±")
            
            # ì·¨ì•½ì  ì •ë³´
            if pkg.get('vulnerabilities'):
                vuln_count = len(pkg['vulnerabilities'])
                sbom_parts.append(f"    âš ï¸ {vuln_count}ê°œ ì•Œë ¤ì§„ ì·¨ì•½ì ")
        
        # ê°„ì ‘ ì¢…ì†ì„±
        indirect = sbom.get('indirect_dependencies', [])
        if indirect:
            sbom_parts.append(f"\nê°„ì ‘ ì¢…ì†ì„±: {len(indirect)}ê°œ")
        
        return "\n".join(sbom_parts)

    def _get_full_conversation_history(self) -> str:
        """ì™„ì „í•œ ëŒ€í™” ê¸°ë¡ (ì˜ë¦¬ì§€ ì•ŠìŒ)"""
        import streamlit as st
        
        qa_messages = st.session_state.get('qa_messages', [])
        if not qa_messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        history = []
        
        # ëª¨ë“  ëŒ€í™” í¬í•¨ (ì œí•œ ì—†ìŒ)
        for i, msg in enumerate(qa_messages):
            if msg["role"] == "user":
                history.append(f"\nì‚¬ìš©ì: {msg['content']}")
            else:
                # ì „ì²´ ë‹µë³€ í¬í•¨ (ì˜ë¦¬ì§€ ì•ŠìŒ)
                content = msg['content']
                # í‘¸í„°ë§Œ ì œê±°
                if '\n\n---\n' in content:
                    content = content.split('\n\n---\n')[0]
                history.append(f"\nAI: {content}")
        
        return "\n".join(history) if history else "ì´ì „ ëŒ€í™” ì—†ìŒ"
    
    # rag/simple_rag.py
# SimpleRAG í´ë˜ìŠ¤ ì•ˆì— ì¶”ê°€ (ë‹¤ë¥¸ ë©”ì„œë“œë“¤ ì•„ë˜ì—)

    def _generate_ai_answer(self, prompt: str) -> str:
        """AI ë‹µë³€ ìƒì„± (Claude ìš°ì„ , GPT í´ë°±)"""
        from prompts.all_prompts import SYSTEM_PROMPTS
        import os
        
        answer = None
        
        # Claude ì‹œë„
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                from anthropic import Anthropic
                claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
                model = os.getenv("ANTHROPIC_MODEL", "claude-3-opus-20240229")
                
                # ClaudeëŠ” systemì„ userì— í¬í•¨
                system_prompt = SYSTEM_PROMPTS.get("qa_expert", "")
                full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
                
                response = claude_client.messages.create(
                    model=model,
                    max_tokens=1500,
                    temperature=0.3,
                    messages=[{"role": "user", "content": full_prompt}]
                )
                
                answer = response.content[0].text
                print("âœ… Claude ë‹µë³€ ìƒì„±")
                
            except Exception as e:
                print(f"âš ï¸ Claude ì‹¤íŒ¨, GPTë¡œ í´ë°±: {e}")
        
        # GPT í´ë°±
        if not answer and os.getenv("OPENAI_API_KEY"):
            try:
                model = os.getenv("OPENAI_MODEL", "gpt-4-turbo-preview")
                
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPTS.get("qa_expert", "Python ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=1500
                )
                
                answer = response.choices[0].message.content
                print("âœ… GPT ë‹µë³€ ìƒì„±")
                
            except Exception as e:
                print(f"âŒ GPTë„ ì‹¤íŒ¨: {e}")
                answer = None
        
        return answer if answer else "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."