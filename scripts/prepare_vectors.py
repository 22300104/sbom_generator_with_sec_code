# scripts/prepare_vectors.py
import pdfplumber
import chromadb
from chromadb.config import Settings
import json
import re
from pathlib import Path

class GuidelineProcessor:
    def __init__(self, pdf_path):
        self.pdf_path = pdf_path
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë¡œì»¬ ì €ì¥)
        self.chroma_client = chromadb.PersistentClient(
            path="data/vector_db",
            settings=Settings(anonymized_telemetry=False)
        )
        
    def extract_pdf_content(self, start_page=8, end_page=50):
        """PDFì—ì„œ í•µì‹¬ í˜ì´ì§€ë§Œ ì¶”ì¶œ (MVPìš©)"""
        print(f"ğŸ“– PDF ì¶”ì¶œ ì¤‘... ({start_page}-{end_page} í˜ì´ì§€)")
        
        extracted_content = []
        
        with pdfplumber.open(self.pdf_path) as pdf:
            for page_num in range(start_page-1, min(end_page, len(pdf.pages))):
                page = pdf.pages[page_num]
                
                # ë ˆì´ì•„ì›ƒ ë³´ì¡´í•˜ë©´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = page.extract_text()
                
                if text:
                    # ì„¹ì…˜ë³„ë¡œ êµ¬ë¶„
                    sections = self._parse_sections(text, page_num + 1)
                    extracted_content.extend(sections)
                    
                print(f"  âœ“ {page_num + 1} í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ")
        
        return extracted_content
    
    def _parse_sections(self, text, page_num):
        """í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ìˆëŠ” ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬"""
        sections = []
        
        # ì£¼ìš” íŒ¨í„´ë“¤
        patterns = {
            'vulnerability': r'^\d+\.\s+(.+?)$',  # "1. SQL ì‚½ì…" ê°™ì€ íŒ¨í„´
            'safe_code': r'ì•ˆì „í•œ ì½”ë“œ ì˜ˆì‹œ',
            'unsafe_code': r'ì•ˆì „í•˜ì§€ ì•Šì€ ì½”ë“œ ì˜ˆì‹œ',
            'description': r'ê°€\.\s*ê°œìš”',
            'solution': r'ë‚˜\.\s*ì•ˆì „í•œ ì½”ë”©ê¸°ë²•'
        }
        
        lines = text.split('\n')
        current_section = {'type': 'general', 'content': [], 'page': page_num}
        
        for line in lines:
            # ì„¹ì…˜ íƒ€ì… ê²°ì •
            for section_type, pattern in patterns.items():
                if re.search(pattern, line):
                    # ì´ì „ ì„¹ì…˜ ì €ì¥
                    if current_section['content']:
                        sections.append({
                            'type': current_section['type'],
                            'content': '\n'.join(current_section['content']),
                            'page': current_section['page']
                        })
                    # ìƒˆ ì„¹ì…˜ ì‹œì‘
                    current_section = {
                        'type': section_type,
                        'content': [line],
                        'page': page_num
                    }
                    break
            else:
                # í˜„ì¬ ì„¹ì…˜ì— ì¶”ê°€
                current_section['content'].append(line)
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section['content']:
            sections.append({
                'type': current_section['type'],
                'content': '\n'.join(current_section['content']),
                'page': current_section['page']
            })
        
        return sections
    
    def create_vector_db(self, content_sections):
        """ChromaDBì— ë²¡í„° ì €ì¥"""
        print("\nğŸ—„ï¸ ë²¡í„° DB ìƒì„± ì¤‘...")
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ìˆë‹¤ë©´)
        try:
            self.chroma_client.delete_collection("secure_coding_guide")
        except:
            pass
        
        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        collection = self.chroma_client.create_collection(
            name="secure_coding_guide",
            metadata={"description": "Python ì‹œíì–´ì½”ë”© ê°€ì´ë“œ"}
        )
        
        # ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        documents = []
        metadatas = []
        ids = []
        
        for idx, section in enumerate(content_sections):
            documents.append(section['content'])
            metadatas.append({
                'type': section['type'],
                'page': section['page']
            })
            ids.append(f"doc_{idx}")
        
        # ë²¡í„° DBì— ì¶”ê°€ (ì²­í‚¹í•´ì„œ ì¶”ê°€)
        batch_size = 100
        for i in range(0, len(documents), batch_size):
            end_idx = min(i + batch_size, len(documents))
            collection.add(
                documents=documents[i:end_idx],
                metadatas=metadatas[i:end_idx],
                ids=ids[i:end_idx]
            )
            print(f"  âœ“ {end_idx}/{len(documents)} ë¬¸ì„œ ì €ì¥")
        
        print(f"âœ… ì´ {len(documents)}ê°œ ì„¹ì…˜ ë²¡í„° DB ì €ì¥ ì™„ë£Œ!")
        return collection

def main():
    # PDF ê²½ë¡œ ì„¤ì •
    pdf_path = "data/guidelines/Python_ì‹œíì–´ì½”ë”©_ê°€ì´ë“œ(2023ë…„_ê°œì •ë³¸).pdf"
    
    if not Path(pdf_path).exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        print("íŒŒì¼ì„ data/guidelines/ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
        return
    
    # ì²˜ë¦¬ ì‹œì‘
    processor = GuidelineProcessor(pdf_path)
    
    # 1. PDF ë‚´ìš© ì¶”ì¶œ (8-50 í˜ì´ì§€: ì£¼ìš” ë³´ì•ˆ í•­ëª©ë“¤)
    content_sections = processor.extract_pdf_content(start_page=8, end_page=50)
    
    # 2. ë²¡í„° DB ìƒì„±
    collection = processor.create_vector_db(content_sections)
    
    # 3. í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
    print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰...")
    test_queries = [
        "SQL ì‚½ì… ë°©ì–´ ë°©ë²•",
        "ì•ˆì „í•œ íŒ¨ìŠ¤ì›Œë“œ ì €ì¥",
        "XSS ê³µê²© ë°©ì§€"
    ]
    
    for query in test_queries:
        results = collection.query(
            query_texts=[query],
            n_results=2
        )
        print(f"\nì§ˆë¬¸: {query}")
        print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results['documents'][0])}ê°œ ì°¾ìŒ")
        if results['documents'][0]:
            print(f"ì²« ë²ˆì§¸ ê²°ê³¼: {results['documents'][0][0][:100]}...")
    
    print("\nâœ… MVP ë²¡í„° DB ì¤€ë¹„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()